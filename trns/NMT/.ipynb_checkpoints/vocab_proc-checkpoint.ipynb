{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "#from to_k_alpha import convert\n",
    "#from utils import *\n",
    "#from utils import *\n",
    "from counter_utils import *\n",
    "from counter_vocab_tuning import *\n",
    "from vocab_preprocess import *\n",
    "from util_functions import *\n",
    "from vocab_tuning_after_bpe import *\n",
    "# from make_bpe_sents import *   .......depricated\n",
    "from utils_for_sents import *\n",
    "\n",
    "#get_filelist, get_sentences, count_from_file,voc_combined,json_read,convert,special_to_normal\n",
    "\n",
    "# 유니코드 한글 시작 : 44032, 끝 : 55199\n",
    "BASE_CODE, CHOSUNG, JUNGSUNG = 44032, 588, 28\n",
    "\n",
    "# 초성 리스트. 00 ~ 18\n",
    "CHOSUNG_LIST = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', \n",
    "                'ㅍ', 'ㅎ']\n",
    "\n",
    "# 중성 리스트. 00 ~ 20\n",
    "JUNGSUNG_LIST = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', \n",
    "                 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "# 종성 리스트. 00 ~ 27 + 1(1개 없음)\n",
    "JONGSUNG_LIST = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', \n",
    "                 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "ch_len = max([len(s) for s in [CHOSUNG_LIST,JUNGSUNG_LIST, JONGSUNG_LIST]])\n",
    "\n",
    "\n",
    "kor_alpha = CHOSUNG_LIST + ['#']*(ch_len - len(CHOSUNG_LIST)) + JUNGSUNG_LIST + ['#']*(ch_len - len(JUNGSUNG_LIST))+JONGSUNG_LIST\n",
    "#kor_alpha = kor_alpha+['_','$']\n",
    "\"\"\"\n",
    "etc = [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "       '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', \n",
    "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',\n",
    "       'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', \n",
    "       'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "       '{', '|', '}', '~']\n",
    "\"\"\"\n",
    "#alpha = [C for C in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"]+[c for c in 'abcdefghijklmnopqrstuvwxyz']\n",
    "#kor_alpha += etc\n",
    "\n",
    "kor_alpha = kor_alpha+[s for s in '0123456789-_']\n",
    "\n",
    "len_alpha =96+BASE_CODE\n",
    "ch_start = chr(len_alpha-1)\n",
    "ch_end = chr(len_alpha-1)\n",
    "#ch_end = chr(len_alpha-1)\n",
    "\n",
    "s_to_double, d_to_single, ch_to_num, num_to_ch = double_vowel_lookup2(JUNGSUNG_LIST)\n",
    "\n",
    "double_vowel =[]\n",
    "for c in 'ㅕㅘㅝㅟㅐ':\n",
    "    double_vowel.append(ch_to_num[c])\n",
    "\n",
    "k_alpha_to_num =[{},{}]\n",
    "for i, s in enumerate(kor_alpha[28:]):\n",
    "    k_alpha_to_num[1][s] = i+28 \n",
    "for i, s in enumerate(kor_alpha[:56]):\n",
    "    k_alpha_to_num[0][s] = i \n",
    "for i in range(2):\n",
    "    k_alpha_to_num[i].pop(' ',1)\n",
    "    k_alpha_to_num[i].pop('#',1)\n",
    "    \n",
    "key_vars = {'BASE_CODE':BASE_CODE,'CHOSUNG':CHOSUNG, 'JUNGSUNG':JUNGSUNG,'ch_len':ch_len,\n",
    "            'kor_alpha':kor_alpha, 'len_alpha':len_alpha, 'ch_start':ch_start,\n",
    "            'CHOSUNG_LIST':CHOSUNG_LIST,'JUNGSUNG_LIST':JUNGSUNG_LIST,'JONGSUNG_LIST':JONGSUNG_LIST,\n",
    "            'double_vowel':double_vowel, 's_to_double':s_to_double, 'd_to_single':d_to_single,\n",
    "            'k_alpha_to_num':k_alpha_to_num }\n",
    "\n",
    "\n",
    "#josa1=[c for c in '가는은를을의에'] \n",
    "josa1=[c for c in '를의'] + '와 과'.split(' ')\n",
    "#josa2 = ['에게','에서', '에는' ] + ['부터', '까지', '없이'] #sec_josa 에서 추가\n",
    "josa2 = ['에게','에서', '에는' ] + ['부터', '까지', '없이'] +'으로 와는 과는 이며 이다 이고 였다 였고'.split(' ')\n",
    "josa3 = '으로는 으로도 까지는 까지도 로부터 에서는 에서도 없이는 없이도 부터는 부터도 에게도'.split(' ')\n",
    "josa2_1 = '한다 하고 하며 하는 된다 되어 되던 되며 되고 되는 했다 했고'.split(' ')\n",
    "josa2 = josa2 + josa2_1\n",
    "josa_all = josa1+josa2+josa3\n",
    "\n",
    "# josa 3 : '이다', '이고', '하고', '하여', '해서', 되어, '하게', '한다', '했다']\n",
    "sec_josa_1 = ['하고', '했다', '였다', '하여', '로', '과', '했고', '하는', '된다']\n",
    "sec_josa_2 = ['되어', '했으며',  '했다', '하다가', '하면서', '되었다', '하였다'] #'까지',\n",
    "sec_josa_3 = ['한다는', '되었던', '하기도', '하였으며', '한다', '했던'] #'없이','부터',  \n",
    "sec_josa_4 = ['하였다', '되며', '되었던', '되었다', '되기도', '될', '받는다', '하였으며', '부터는', '되었고', '되는', '받고', \n",
    "              '하면', '한다', '하였고', '된']\n",
    "sec_josa_5 = ['하거나', '되었으며', '되던']\n",
    "sec_josa_6 = '이다 이며 에서는 에서도 으로는 로는 로부터 으로부터 였으며 였던 는 은 을 에 로 가'.split(' ')\n",
    "sec_josa_7 = '당하다 당하는 당하고 당하면 당해서 당해 당했기 당했다 당했고 당하여 게된다 게되고 게되다 게되는 게되었고 게되었다 게되어서'.split(' ')\n",
    "sec_josa = sec_josa_1+ sec_josa_2 + sec_josa_3 + sec_josa_4 + sec_josa_5 + sec_josa_5 +sec_josa_6+sec_josa_7\n",
    "\n",
    "sec_josa = josa1 + josa2 + sec_josa\n",
    "sec_josa = list(set(sec_josa))\n",
    "\n",
    "\n",
    "noun_josa =['될', '을', '과', '를', '의', '은', '된', '에', '로', '가', '는', '와', \n",
    "            '받고', '에는', '에게', '였다', '당해', '에서', '되며', '이며', '하면', '하는', '되어', '했고', '와는', \n",
    "            '하며', '한다', '이고', '되는', '과는', '으로', '하여', '였던', '하고', '된다', '했다', '였고', '부터', \n",
    "            '했던', '되던', '되고', '로는', '까지', '이다', '없이', '되다'\n",
    "            '당해서', '당하고', '당하는', '하다가', '당하여', '당했다', '하기도', '에서도', '받는다', '되기도', \n",
    "            '하였고', '에서는', '한다는', '하였다', '로부터', '당했고', '하면서', '당하다', \n",
    "            '되었다', '했으며', '하거나', '되었고', '당하면', '부터는', '되었던', '으로는', \n",
    "            '당했기', '였으며', \n",
    "            '으로부터', '되었으며', '하였으며']\n",
    "\n",
    "noun_josa = list(set(noun_josa))\n",
    "\n",
    "sec_noun_josa = noun_josa\n",
    "# noun_josa 는  noun을 찾는데... sec_noun_josa 는 '는 은 을 를 은 로 가'까지 적용하는 데 사용\n",
    "for s in '는 은 을 를 은 로 가'.split(' '):\n",
    "    if s in noun_josa: noun_josa.remove(s)\n",
    "\n",
    "to_find_josa = ['__이루', '이끌', '__보이', '__가지', '__이루어지', '__떨어지', '__세우', '__이ㅓㄹ리', '__쓰이', '__내리', '__일으키',\n",
    "                '__이어지', '__줄이', '__빠지', '__생기', '__붙이', '__사라지', '__지키', '__바꾸', '__싸우', '__치', \n",
    "                '__느끼', '__있', '__그리', '__하', '__없', '__않', '__되', '__알리ㅓ지', '__사용하', '__밝히', '__불리',\n",
    "                '__주', '__높이', '__이루', '__올리', '__만들어지', '__지니', '__모이', '__옮기', '__벌이', '__미치', \n",
    "                '__죽이', '__배우', '__알리', '__피ㅓㄹ치', '__받아들이', '__지', '__벌어지', '__시키', '__가르치', \n",
    "                '__이ㅓ기ㅓ지', '__이ㅓ기', '__전해지', '__이기', '__던지', '__늘리', '__거치', '__속하', '__받', '__두', \n",
    "                '__갖', '__보', '__못하', '__가', '__나오', '__등장하', '__맡', '__이르', '__쓰', '__존재하', '__부르', \n",
    "                '__호ㅏㄹ동하', '__다르', '__듣', '__나타나', '__남기', '__일어나', '__발생하', '__차지하', '__입', \n",
    "                '__보이ㅓ주', '__오', '__맺', '__잡', '__접하', '__내', '__죽', '__얻', '__잃', '__버리', '__담당하', \n",
    "                '__찾', '__맞', '__따르', '__가능하', '__짓', '__끝나', '__시작하', '__보내', '__들어가', \n",
    "                '__움직이', '__맞추', '__참가하', '__생각하', '__걸리', '__만나', '__놓이', '__참이ㅓ하', '__향하', \n",
    "                '__띠', '__나가', '__일하', '__다니', '__히ㅓㅇ성하', '__달리', '__당하', '__공기ㅓㄱ하', '__오르', \n",
    "                '__고치', '__거두', '__돌리', '__나누', '__띄', '__돌아가', '__떠나', '__비ㅓㄴ하', '__높아지', '__낳',\n",
    "                '__치르', '__넘기', '__행해지', '__발전하']\n",
    "\n",
    "to_find_josa2 = ['__아름다', '__즐거', '__가까', '__괴로',  '__나ㅣ세', \n",
    "                '__어두', '__외로', '__놀라', '__무거', '__두터', '__자유로', \n",
    "                '__앞세', '__부드러', '__무서', '__부끄러', \n",
    "                '__뜨거', '__고마', '__안타까', \n",
    "                '__두꺼', '__혼란스러', '__팔아치',  \n",
    "                '__갈아치',  '__번거로', '__고통스러', '__풍요로', \n",
    "                '__날카로', '__꽃피','__부러',  '__부담스러', '__어지러', \n",
    "                '__자이ㅓㄴ스러']\n",
    "\n",
    "\n",
    "to_find_words = 'ㅓㅆ다 게 면 ㅓ서 ㅓ 는 고 지만 ㅓㅆ고 ㅓㅆ지만'.split(' ')\n",
    "\n",
    "to_find_irregular = 'ㅂ게 ㅂ다 ㅂ고 ㅂ지 워 운'\n",
    "\n",
    "\n",
    "\n",
    "def bpe_vocab_initialize():\n",
    "    \n",
    "    path = './generated_Data4/'\n",
    "    file_list = get_filelist()\n",
    "    bpe_vocabs = vocab_build(file_list,key_vars,from_file=True)\n",
    "    json_save(bpe_vocabs, path+'vocabs_'+ str(0))\n",
    "    return bpe_vocabs\n",
    "\n",
    "#bpe_vocabs = bpe_vocab_initialize\n",
    "\n",
    "\n",
    "def bpe_voc_in_normal(bpe_vocabs):\n",
    "    voc_ex, _ = voc_combined(bpe_vocabs)\n",
    "    sorted_voc_ex = sorted(voc_ex.items(), key=lambda x:x[1], reverse=True)\n",
    "    readable = [(special_to_normal(k,key_vars),v) for k, v in sorted_voc_ex]\n",
    "    return readable, sorted_voc_ex\n",
    "\n",
    "\n",
    "def to_make_josa_list(words_with_josa):\n",
    "    \n",
    "    josa_found = [v for k,v in words_with_josa]\n",
    "    josa ={}\n",
    "    for j in josa_found:\n",
    "        if j in josa.keys():\n",
    "            josa[j] +=1\n",
    "        else:\n",
    "            josa[j] =1\n",
    "\n",
    "    josa_to_apply = sorted(josa.items(), key=lambda x:x[1], reverse=True)\n",
    "    josa_to_apply = [k for k,v in josa_to_apply]\n",
    "    josa_list ={}\n",
    "    josa_to_apply = josa_to_apply[:300]\n",
    "    max_l = max([len(j) for j in josa_to_apply])\n",
    "    for i in range(max_l+1):\n",
    "        josa_list[i] =[]\n",
    "    for j in josa_to_apply:   \n",
    "        josa_list[len(j)].append(j)\n",
    "    \n",
    "    return josa_list\n",
    "\n",
    "\"\"\" \n",
    "def find_to_tune_2(sorted_vocabs,josa_list,key_vars,cutline, num_of_letters): #vocabs: list of tuple\n",
    "    #nums = [n for n in '0123456789']\n",
    "    #numbers =[]\n",
    "    j_len = len(josa_list)\n",
    "    words_with_s = []\n",
    "    candidate_with_j = {}\n",
    "    p=re.compile(r'[0-9가-힣]')\n",
    "    for s,v in tqdm(sorted_vocabs):\n",
    "        k = special_to_normal(s,key_vars)\n",
    "        #print(k)\n",
    "        if (len(k)>3):\n",
    "            for i in reversed(range(1,j_len)):\n",
    "                 \n",
    "                #print(i)\n",
    "                if i>len(k)-1:continue\n",
    "                if k[-i:] in josa_list[i]:\n",
    "                    if k[:-i] in candidate_with_j.keys():\n",
    "                        candidate_with_j[k[:-i]] += 1\n",
    "                    elif p.match(k[-(i+1)]): \n",
    "                        candidate_with_j[k[:-i]] = 1\n",
    "                    break\n",
    "               \n",
    "\n",
    "    words_to_tune = {}\n",
    "    for k,v in candidate_with_j.items():\n",
    "        if (v >cutline):\n",
    "            words_to_tune[k] = v\n",
    "\n",
    "    return adjust_word_to_tune(words_to_tune, num_of_letters) # 두 글자 이상만 반영   \n",
    "    #return words_to_tune\n",
    "\n",
    "\n",
    "def vocab_tunning2(vocabs, to_tune, josa, key_vars):\n",
    "    #to_tune = [normal_to_special(k,key_vars) for k,v in words_to_tune.items()]\n",
    "    #to_tune = [k for k,v in words_to_tune.items()]\n",
    "    #josa = [normal_to_special(j,key_vars) for j in josa1 +josa2]\n",
    "    #josa = josa1 +josa2\n",
    "    tuned_vocabs1 = {}\n",
    "    tuned_vocabs2 = {}\n",
    "    to_delete = {}\n",
    "    separated_terms = []\n",
    "    #=re.compile(r'[0-9가-힣]')\n",
    "    for k,v in tqdm(vocabs.items()):\n",
    "        w = []\n",
    "        num_tune = 0\n",
    "        for sc in k.split(' '):\n",
    "            c = special_to_normal(sc,key_vars)\n",
    "            #print(c)\n",
    "            if len(c) > 2:\n",
    "                n = 0\n",
    "                for i in range(1,len(josa)):\n",
    "                    if (c[:-i] in to_tune) and (c[-i:] in josa[i]):\n",
    "                        w +=[normal_to_special(c[:-i],key_vars), \"_걟\"+normal_to_special(c[-i:],key_vars)]\n",
    "                        separated_terms.append(c)\n",
    "                        num_tune += 1\n",
    "                        n += 1\n",
    "                        break\n",
    "                    if i>len(c)-1:\n",
    "                        break\n",
    "                \n",
    "                if n == 0:w.append(sc)\n",
    "                \n",
    "            else:\n",
    "                w.append(sc)\n",
    "\n",
    "        if num_tune > 0:\n",
    "            k1,k2 = ' '.join(w).split(' _')\n",
    "\"\"\"\n",
    "            #tuned_vocabs1.append(k1)\n",
    "            #tuned_vocabs2.append(k2)\n",
    "            #to_delete.append((k,v))\n",
    "\"\"\"\n",
    "\n",
    "            tuned_vocabs1 = add_dict_item(k1,v,tuned_vocabs1)\n",
    "            tuned_vocabs2 = add_dict_item(k2,v,tuned_vocabs2)\n",
    "\n",
    "            to_delete[k] = v\n",
    "          \n",
    "            \n",
    "    return tuned_vocabs1, tuned_vocabs2, separated_terms, to_delete    \n",
    "    \n",
    "\"\"\"    \n",
    "def extract_bpe_sentences_from_normal():\n",
    "    file_list = get_filelist()\n",
    "    sentences = call_sentences(file_list, num_files=2)\n",
    "    vocs, _ = voc_combined(pre_bpe_vocabs)\n",
    "    vocabs_to_get_sents = {}\n",
    "    p = re.compile('^걟')\n",
    "    for k, v in vocs.items():\n",
    "        vocabs_to_get_sents[p.sub('',k)] = v\n",
    "    return sentences, vocabs_to_get_sents\n",
    "\n",
    "\n",
    "def to_eval_whether_to_split3(voc_f,vocs_1ch,vocs_count, iter_sum, pre_sum, km, kd, key_vars):\n",
    "\n",
    "    print('start process of [to_eval_whether_to_split]')\n",
    "    new_vocs = {}\n",
    "    new_voc_f = {}\n",
    "    vf ={} \n",
    "    vc ={}\n",
    "    #selected = ''\n",
    "    after_comb = np.zeros((2,))\n",
    "    before_comb = np.zeros((2,))\n",
    "    eval_comb = []\n",
    "    s_vocs = sorted(voc_f.items(), key=lambda x:x[1][1], reverse=True)\n",
    "    for ix,(k,v) in enumerate(tqdm(s_vocs)):\n",
    "        #print(v[1], voc_f[v[0][0]][1], voc_f[v[0][1]][1])\n",
    "        #print(special_to_normal(v[0][0], key_vars), special_to_normal(v[0][1], key_vars))\n",
    "        for i,c in enumerate([v[0][0],v[0][1]]):\n",
    "            vf[i] = voc_f[c][1] if len(c) >1 else vocs_1ch[c]     # voc_f : {key:[[v01,vo2],v1]}\n",
    "            vc[i] = vocs_count[c] if len(c) >1 else vocs_1ch[c] \n",
    "        after_comb[0] = np.log(v[1]/iter_sum)\n",
    "        before_comb[0] = np.log(vf[0]/iter_sum) + np.log(vf[1]/iter_sum)\n",
    "        after_comb[1] = np.log(vocs_count[k]/pre_sum) \n",
    "        before_comb[1] = np.log(vc[0]/pre_sum)+np.log(vc[1]/pre_sum)\n",
    "        eval_comb.append(np.concatenate((after_comb, before_comb),0))\n",
    "        \n",
    "        if ix < 70000:\n",
    "            new_vocs[k] = v[1]\n",
    "            new_voc_f[k] = [(v[0][0],v[0][1]),v[1]]\n",
    "        elif ((after_comb[0] > before_comb[0]+1.5/70000* ix-0.5) \n",
    "              or (after_comb[1] > before_comb[1]+2.5/70000* ix-1.3)):\n",
    "            new_vocs[k] = v[1]\n",
    "            new_voc_f[k] = [(v[0][0],v[0][1]),v[1]]\n",
    "\n",
    "            \n",
    "        #print(\"preprocessed : {}, {}, {}\".format(after_comb[0], before_comb[0], selected)) \n",
    "        #print(\"original_bpe : {}, {}\".format(after_comb[1], before_comb[1]))\n",
    "        #selected = ''\n",
    "    deleted_items, replaced_items = dict_merge(vocs_1ch, new_vocs)\n",
    "    return  new_vocs, new_voc_f,eval_comb\n",
    "\n",
    "def get_new_vocs():\n",
    "    import numpy as np\n",
    "\n",
    "    iter_num = '70000'\n",
    "    f_path ='./generated_Data11/bpe/vocs_freq'+iter_num+'.json'\n",
    "    voc_f = json_read(f_path)\n",
    "\n",
    "    bpe_vocabs, split_bpe_vocabs = get_split_bpe_vocabs()\n",
    "    voc_1ch = get_single_char_freq(split_bpe_vocabs)\n",
    "    voc_1ch['걟'] = sum(json_read('./generated_Data11/preproc/josa_vocabs_008_after_n_c0_n1.json').values())\n",
    "\n",
    "    vocs_count = json_read('./generated_Data11/bpe/voc_count_70000.json')\n",
    "    iter_vocabs =json_read('./generated_Data11/bpe/vocabs'+iter_num+'.json')\n",
    "\n",
    "    iter_sum = sum(iter_vocabs.values())\n",
    "    pre_sum = sum(bpe_vocabs.values())\n",
    "    km = 1.\n",
    "    kd = 4000\n",
    "\n",
    "    new_vocs, new_voc_f, eval_comb = to_eval_whether_to_split3(\n",
    "        voc_f,voc_1ch,vocs_count, iter_sum, pre_sum, km, kd, key_vars)\n",
    "\n",
    "    vcs = [[],[],[],[]]\n",
    "    for i in range(4):\n",
    "        vcs[i] = [s[i] for s in eval_comb]\n",
    "    \n",
    "    return new_vocs, vocs_count\n",
    "\n",
    "def extract_bpe_sentences_from_normal3(vocabs, num_files=2):\n",
    "    file_list = get_filelist()\n",
    "    sentences = call_sentences(file_list, num_files)\n",
    "    #vocabs = json_read(path+file)\n",
    "    vocs, _ = voc_combined(vocabs)\n",
    "    \"\"\"\n",
    "    vocabs_to_get_sents = {}\n",
    "    p = re.compile(r'걟걟$')\n",
    "    for k, v in vocs.items():\n",
    "        insert_voc(vocabs_to_get_sents, p.sub('걟',k), v)\n",
    "    \"\"\"\n",
    "    return sentences, vocs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12155302e1b24d14bd2f1da46a0c31f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cee51a1f8884948b34423ff1ae9d6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "updated items : 1,  added items : 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c516391974a745f5a9fa98d3c215796a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "updated items : 19,  added items : 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4767d69b734299904a563e30565038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=58.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "updated items : 5,  added items : 53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f2e251eb30473bad2600981bb86aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2922008e5884315a3d7075864b505ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fbeb95f49d4ecb9d9013fbe7cd219e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "updated items : 18,  added items : 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006c67a54fb9433a959c2822af48d327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "updated items : 0,  added items : 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nlogprob = log_prob_by_len3(vocabs)\\nsum_voc_vals = sum(vocabs.values())\\n\\n#single_words = json_read('./en_es_after_0406/ko_single_words.json')\\n#vocabs.update({normal_to_special(k,key_vars):max(v,300) for k, v in single_words.items()})\\n\\nimport copy\\nvocs_dict = [{},{}]\\nvocs_dict[0] = copy.deepcopy(vocabs)\\nvocs_dict[1] = copy.deepcopy(vocabs)\\nfor i in range(2):\\n    for k,l in vocs_dict[i].items():\\n        vocs_dict[i][k] = k\\n        \\n#extracted_vocs = json_read('./generated_Data11/preproc_0311/extracted_vocabs_nvs.json')\\n\\nfor i in tqdm(range(1,5)):\\n    df = pd.read_excel('./../Data/3_문어체_뉴스('+str(i)+')_191213.xlsx')\\n    parallel = df['ID 원문 번역문'.split(' ')]\\n    test_all_data = parallel[parallel['ID']%8 == 0]\\n    test_data = parallel[parallel['ID']%80 == 0]\\n    dev_data = parallel[parallel['ID']%8 == 4]\\n    train_data = parallel[parallel['ID']%4 != 0]\\n\\n    data_nm = 'test test_all dev train'.split(' ')\\n    #path = './en_es_data_3/'\\n    save_op = 'w' if i==1 else 'a'\\n    for j,ds in enumerate(tqdm([test_data, test_all_data, dev_data, train_data])): \\n        X = ds['원문']\\n        #X = to_bpe_sents8_test(X, vocabs,key_vars, sum_voc_vals)\\n        #  (1.3,3.2,14,1 (1.5,2.9,14,-1)  (1.3,2.8,14,0)\\n        X = to_bpe_sents10(X, vocabs,vocs_dict, logprob, key_vars, sum_voc_vals,extracted_vocs,(1.3,3.2,20,1),(6,5)) #default (1,3,12)\\n        print(X[:5])\\n        #X = to_normal_sents4(X, vocabs, josas, keywords, verbs, comb_check, key_vocs,key_vars, etc)\\n        _ = save_sents(X, path+data_nm[j]+'.ko',save_op)\\n \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after 50000 iteration magic discrete line k=1\n",
    "#\n",
    "#######################################################\n",
    "\n",
    "####              Final Version\n",
    "\n",
    "#######################################################\n",
    "\n",
    "\n",
    "def save_sents(sentences,fn,save_op):\n",
    "    p=re.compile(r'\\.$')\n",
    "    q = re.compile(r'\\s+')\n",
    "    z = re.compile(r'_ ') #영어로 번역할 때는 '_' 무시\n",
    "    u = re.compile(r'(?P<to_fix>[0-9]+)')\n",
    "                 \n",
    "    sents = []\n",
    "    for s in sentences:\n",
    "        sents.append(q.sub(' ',u.sub(' \\g<to_fix> ',z.sub(' ',p.sub(' .',' '.join(s))))))\n",
    "        \n",
    "        #sents.append(z.sub(' ',q.sub(' ',p.sub(' .',' '.join(s)))))\n",
    "        \n",
    "    to_save = '\\n'.join(sents)   \n",
    "\n",
    "    with open(fn,save_op) as f:\n",
    "        f.write(to_save)  \n",
    "    \n",
    "    return to_save\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "#df = pd.DataFrame()\n",
    "\n",
    "\n",
    "#vocabs = to_get_vocabs2()\n",
    "date_now = time.strftime('%Y_%m_%d_%H_%M', time.localtime(time.time()))\n",
    "path = \"./en_es_after_0413/\"\n",
    "\n",
    "#json_save(vocabs, './generated_Data11/preproc_0301/vocabs_for_sents5_'+date_now)\n",
    "\n",
    "\n",
    "#new_vocs, vocs_count = get_new_vocs()\n",
    "#temp_vocabs = new_vocs\n",
    "#sentences, _ = extract_bpe_sentences_from_normal3(new_vocs)\n",
    "#vocabs = json_read('./generated_Data11/bpe/vocabs_for_sents5_2020_02_26_15_39.json')\n",
    "#vocabs[''] = 0.00001\n",
    "#vocabs['NotInVocabs'] = 0.001\n",
    "#logprob = log_prob_by_len3(vocabs)\n",
    "#vocs_dict = get_vocs_dict(vocabs)\n",
    "#josas, keywords, verbs,comb_check, key_vocs, etc = get_vocs_group(vocabs,key_vars)\n",
    "\n",
    "def dict_max(src1,src2):\n",
    "    import copy\n",
    "    tgt = copy.deepcopy(src2)\n",
    "    for k,v in src1.items():\n",
    "        if k in tgt.keys():\n",
    "            tgt[k] = max(v,tgt[k])\n",
    "        else:\n",
    "            tgt[k] = v\n",
    "    return tgt\n",
    "\n",
    "\"\"\"\n",
    "iter_vocs = json_read('./generated_Data11/bpe_0315/vocabs70000.json')\n",
    "_,bp_vocs_tpl = bpe_voc_in_normal(iter_vocs)\n",
    "bp_vocs_dict = {k:v for (k,v) in bp_vocs_tpl}\n",
    "\n",
    "new_vocs_small = json_read('./generated_Data11/preproc_0315/new_vocs_small.json')\n",
    "bpe_vocs = dict_max(new_vocs_small,bp_vocs_dict)\n",
    "new_vocs = bpe_vocs\n",
    "\"\"\" \n",
    "new_vocs = json_read('./generated_Data11/preproc_0315/new_vocs_small.json')\n",
    "new_vocs_small = new_vocs\n",
    "\n",
    "extracted_vocs = json_read('./generated_Data11/preproc_0311/extracted_vocabs_nvs.json')\n",
    "\n",
    "\n",
    "to_adjust = ['스러우','스럽','시끄러우','따가우','까끄러우','안쓰러우','부드러우','껄끄러우','보드라우','어려우','싱그러우','부끄러우','무서우']\n",
    "to_adjust += ['움직이','반짝이','담그',',담기','결정지','가지','데치','무치','걷히','열리','사라지','덧붙이','오르','줄어드']\n",
    "to_adjust += ['치러지','내리','거세지','기울이','깨우치','이어지','놓이','만들','들이받','머뭇거리','끈질기','빠지','졸리','견디']\n",
    "to_adjust += ['어긋나','뒤늦','엉기','엉키','고꾸라지','돌이키','모이','지피']\n",
    "to_adjust_2 = ['테크노','밸리','피플','플랫','사커','큐빅','클린','베이','레이서','유니버시티','도널드','메타포','데일리','잉글리시']\n",
    "to_adjust_2 += ['슬리핑','숄더','도그','코펜하겐','며느리','종로','국영','민영','고법','병원','임시','방공식별','김정은','겨자']\n",
    "to_adjust_2 += ['훈','관','영','근','인','순', '그들', '이들','말치레']\n",
    "to_adjust_2 += ['국제','식민','콰이어','코러스','최고','최저','최소','최대','별도','통째','일련','애잔','예비','즉각','어처구니','휴양']\n",
    "to_adjust_3 = ['일수록','므로', '나마','야말로','자마자','만큼','토록']\n",
    "to_skip = ['구한말']\n",
    "to_split = {'자가':'자 가','자의':'자 의','제로':'제 로','성과':'성 과','적인':'적 인','ㅁ을':'ㅁ 을', '도가':'도 가',\n",
    "            '세에':'세 에','위에':'위 에','수의':'수 의','력이':'력 이','권에':'권 에','ㅁ이':'ㅁ 이','결의':'결 의',\n",
    "            '양이':'양 이','상이':'상 이','진이':'진 이','특유의':'특유 의','가의':'가 의','차로':'차 로','사가':'사 가'\n",
    "           }\n",
    "to_adjust = list(set(to_adjust))\n",
    "to_adjust_2 = list(set(to_adjust_2))\n",
    "\n",
    "vocabs = new_vocs\n",
    "\n",
    "# new_vocs_small 을 적용한 것은 vocabs 를 적용하는 경우에 비해 교란 요인을 줄이기 위함 임\n",
    "_, nouns, verbs, subs = vocab_adjust(new_vocs_small,to_adjust, 0.9,to_skip,to_match=2) #to_match:'스러우' 등 중간에 들어가는 표현 수\n",
    "\n",
    "dkey = [ 'nouns', 'verbs', 'subs']\n",
    "for i,dct in enumerate([nouns, verbs, subs]):\n",
    "    _,_ = dict_merge(dct,extracted_vocs[dkey[i]])\n",
    "    \n",
    "_, _, nouns, _ = vocab_adjust(new_vocs_small,to_adjust_2, 0.5)\n",
    "_, _, subs, _ = vocab_adjust(new_vocs_small,to_adjust_3, 0.7, to_match=len(to_adjust_3))\n",
    "\n",
    "dkey = [ 'nouns', 'subs']\n",
    "for i,dct in enumerate([nouns, subs]):\n",
    "    _,_ = dict_merge(dct,extracted_vocs[dkey[i]])\n",
    "    \n",
    "    \n",
    "############# Total Vocabs => 50000 + epsilone + single_words\n",
    "\n",
    "vocabs = {k:v/100. for k,v in vocabs.items() if v>300}\n",
    "\n",
    "#extracted_vocs['nouns'] = {k:v for k,v in extracted_vocs['nouns'].items()}\n",
    "vocabs.update(extracted_vocs['nouns'])\n",
    "\n",
    "vocabs.pop('',1)\n",
    "\n",
    "new_X = copy.deepcopy(vocabs)\n",
    "for k,v in new_X.items(): \n",
    "    normX = special_to_normal3(k,key_vars,keep_double=False)\n",
    "    if len(normX)>1 and normX[-1] in ['제','의','로','이','은','도']:\n",
    "        vocabs[k] = vocabs[k] /10.\n",
    "    if ord(normX[0]) in range(12593, 12644) or ord(normX[-1]) in range(12593, 12644):\n",
    "        vocabs.pop(k,1)\n",
    "\n",
    "for k in ['ㄴ다','ㄴ다는','ㄴ지','ㄴ데','ㄴ다면','ㄴ지는','ㅁ으로써','ㅁ에','ㅁ을','ㄹ지', 'ㄹ지는','ㅣ','ㅣㅆ','ㅆ다', 'ㅆ는','여','였']:\n",
    "    extracted_vocs['subs'].pop(normal_to_special(k,key_vars),1)\n",
    "    extracted_vocs['mids'].pop(normal_to_special(k,key_vars),1)\n",
    "\n",
    "extracted_vocs['verbs'] = {k:v*5 for k,v in extracted_vocs['verbs'].items()} \n",
    "extracted_vocs['subs'] = {k:v*2 for k,v in extracted_vocs['subs'].items()} \n",
    "extracted_vocs['mids'] = {k:v*2 for k,v in extracted_vocs['mids'].items()} \n",
    "\n",
    "vocabs.update(extracted_vocs['verbs'])\n",
    "vocabs.update(extracted_vocs['subs'])\n",
    "vocabs.update(extracted_vocs['mids'])\n",
    "\n",
    "for k in ['내려','담겨있','후보이','기에']:\n",
    "    vocabs.pop(normal_to_special(k,key_vars),1)\n",
    "    \n",
    "vocabs.pop('',1)    \n",
    "new_X = copy.deepcopy(vocabs)\n",
    "for k,v in new_X.items(): \n",
    "    normX = special_to_normal3(k,key_vars,keep_double=False)\n",
    "    if normX[0] in ['눠','춰','눴','췄','봐','봤','였']:\n",
    "        vocabs[k] = vocabs[k] /100.\n",
    "    if len(normX)>1 and normX[0] in '않 앉 없 있 받 싶 찾 잦 갚'.split(' '):\n",
    "        vocabs[k] = vocabs[k] /100.\n",
    "\n",
    "single_words = json_read('./en_es_after_0406/ko_single_words.json')\n",
    "vocabs.update({normal_to_special(k,key_vars):max(v,100) for k, v in single_words.items() \n",
    "              if ord(k) not in range(12593, 12644)})\n",
    "\n",
    "vocabs.pop('',1)\n",
    "\n",
    "    \n",
    "for k in 'ㄴ ㄹ ㅁ 쳐'.split(' '):\n",
    "    vocabs[normal_to_special(k,key_vars)] = vocabs[normal_to_special(k,key_vars)] /10.\n",
    "\n",
    "#############\n",
    "\n",
    "\n",
    "w_to_tune = '가 이 는 여 를 론 일 있 않 앉 없 받 싶 순 찾 갖 맞 잦 갚 녹 간 주의 김 성장 과제 절실 도시 이유 특유 거뜬 ㅅ'.split(' ')\n",
    "w_to_tune += \"전략 매우 다소 아름 모든 되레 이용 대거 나름대로 어떻게 더욱 역시 결정 아들 직접 간접 마음껏 결코 통째 흔히\".split(' ')\n",
    "w_to_tune += \"이미 미리 반면 여러 임시 바로 종일 저절로 따로 즉각 아무리 다시 또한 아울러 절레 착한 개관\".split(' ')\n",
    "w_to_tune += \"과연 조만간 점점 오로지 어쩌면 오히려 전혀 또는 그냥 재차 이를테면 예를들면\".split(' ')\n",
    "\n",
    "w_to_tune += ['제'+str(i) for i in range(10)]\n",
    "w_to_tune = list(set(w_to_tune))\n",
    "\n",
    "for w in w_to_tune:\n",
    "    ws = normal_to_special(w,key_vars)\n",
    "    #print(ws, w)\n",
    "    if ws in vocabs.keys():\n",
    "        vocabs[ws] = max(1000,vocabs[ws]*30) \n",
    "    else:\n",
    "        vocabs[ws] = 1000 \n",
    "for w in ['로','의']:\n",
    "    ws = normal_to_special(w,key_vars)\n",
    "    vocabs[ws] = vocabs[ws]*100\n",
    "\"\"\"\n",
    "#w_to_tune = 'ㄴ ㄹ ㅁ'.split(' ')\n",
    "#for w in w_to_tune:\n",
    "#    ws = normal_to_special(w,key_vars)\n",
    "#    #print(ws, w)\n",
    "#    vocabs[ws] = vocabs[ws] * .2\n",
    "\"\"\"\n",
    "    \n",
    "vocabs.pop('',1)\n",
    "_ = vocab_split(vocabs,to_split, 1.0)\n",
    "\n",
    "\n",
    "vocabs.pop(normal_to_special('러운',key_vars),1)\n",
    "vocabs['NotInVocabs'] = 1\n",
    "\n",
    "json_save(vocabs,path+'vocabs')\n",
    "\"\"\"\n",
    "logprob = log_prob_by_len3(vocabs)\n",
    "sum_voc_vals = sum(vocabs.values())\n",
    "\n",
    "#single_words = json_read('./en_es_after_0406/ko_single_words.json')\n",
    "#vocabs.update({normal_to_special(k,key_vars):max(v,300) for k, v in single_words.items()})\n",
    "\n",
    "import copy\n",
    "vocs_dict = [{},{}]\n",
    "vocs_dict[0] = copy.deepcopy(vocabs)\n",
    "vocs_dict[1] = copy.deepcopy(vocabs)\n",
    "for i in range(2):\n",
    "    for k,l in vocs_dict[i].items():\n",
    "        vocs_dict[i][k] = k\n",
    "        \n",
    "#extracted_vocs = json_read('./generated_Data11/preproc_0311/extracted_vocabs_nvs.json')\n",
    "\n",
    "for i in tqdm(range(1,5)):\n",
    "    df = pd.read_excel('./../Data/3_문어체_뉴스('+str(i)+')_191213.xlsx')\n",
    "    parallel = df['ID 원문 번역문'.split(' ')]\n",
    "    test_all_data = parallel[parallel['ID']%8 == 0]\n",
    "    test_data = parallel[parallel['ID']%80 == 0]\n",
    "    dev_data = parallel[parallel['ID']%8 == 4]\n",
    "    train_data = parallel[parallel['ID']%4 != 0]\n",
    "\n",
    "    data_nm = 'test test_all dev train'.split(' ')\n",
    "    #path = './en_es_data_3/'\n",
    "    save_op = 'w' if i==1 else 'a'\n",
    "    for j,ds in enumerate(tqdm([test_data, test_all_data, dev_data, train_data])): \n",
    "        X = ds['원문']\n",
    "        #X = to_bpe_sents8_test(X, vocabs,key_vars, sum_voc_vals)\n",
    "        #  (1.3,3.2,14,1 (1.5,2.9,14,-1)  (1.3,2.8,14,0)\n",
    "        X = to_bpe_sents10(X, vocabs,vocs_dict, logprob, key_vars, sum_voc_vals,extracted_vocs,(1.3,3.2,20,1),(6,5)) #default (1,3,12)\n",
    "        print(X[:5])\n",
    "        #X = to_normal_sents4(X, vocabs, josas, keywords, verbs, comb_check, key_vocs,key_vars, etc)\n",
    "        _ = save_sents(X, path+data_nm[j]+'.ko',save_op)\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56b434afb164361b0493bd11358e380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172b2c4a282c45b580ce87b40d8bdc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['항공', '»', '촬영', '»', '직후에는', '»', '곧바로', '»', '쓸모있게', '»', '촬영되었는지', '»', '검사하여', ',', '»', '총', '»', '488', '시간', '»', '분량의', '»', '필름을', '»', '얻을', '»', '수', '»', '있었다', '.']\n",
      "s : ['이', '»', '영화는', '»', '6', '월', '»', '14', '일까지', '»', '무료로', '»', '14', '개', '»', '언어로', '»', '방송되었다', '.', '»', '블루레이', '»', '버전은', '»', '20', '세기', '»', '폭스에서', '»', '발표하였으며', ',', '»', '약', '»', '10', '만장', '»', '이상이', '»', '판매될', '»', '것으로', '»', '기대하고', '»', '있다', '.']\n",
      "s : ['2001', '년', ',', '»', 'SNK', '가', '»', '도산한', '»', '이후', '»', '메탈슬러그', '»', '4', '»', ',', '다른', '»', 'SNK', '»', '게임', '»', '제작과', '»', '일본', '»', '및', '»', '북미로', '»', '수출을', '»', '발표했고', ',', '»', '2002', '년에', '»', '발매했다', '.', '»', '2006', '년에는', '»', 'SNK', '»', '플레이모어의', '»', '한국', '»', '지사인', '»', 'SNK', '»', 'NEOGEO', '»', 'KOREA', '를', '»', '설립했다', '.']\n",
      "s : ['2005', '년', '»', '8', '월', '»', '12', '일에는', '»', 'MBC', '»', '게임을', '»', '통해', '»', '킹', '»', '오브', '»', '파이터즈를', '»', '방영했다', '.', '»', '같은해', '»', '12', '월에는', '»', '랭킹', '»', '포인트', '»', '5', '만점', '»', '이상', '»', '선수에', '»', '한해', '»', '킹', '»', '오브', '»', '파이터즈', '»', '한일전', '»', '선수를', '»', '모집했다', '.', '»', '2006', '년', '»', '1', '월', '»', '15', '일에는', '»', '철권', '»', '5', '»', '다크', '»', '리저렉션의', '»', '한국', '»', '최강', '»', '결정전을', '»', '개최했다', '.']\n",
      "s : ['브라우저', '»', '게임', '(', 'browser', '»', 'game', ')', '»', '또는', '»', '웹', '»', '게임', '(', 'web', '»', 'game', ')', '은', '»', '인터넷', '»', '연결로', '»', '즐길', '»', '수', '»', '있는', '»', '비디오', '»', '게임을', '»', '뜻한다', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:91: RuntimeWarning: divide by zero encountered in log\n",
      "/home/john/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:110: RuntimeWarning: divide by zero encountered in log\n",
      "/home/john/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:345: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e2983197544010bc3b0a2a48aba9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range, id = 3668\n",
      "list index out of range, id = 5856\n",
      "list index out of range, id = 7168\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cbce4c5cc6439eaf0b54862db02142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['이', '»', '3', '자리', '»', '값과', '»', '16', '자리', '»', '카드', '»', '번호를', '»', '정해진', '»', '규칙에', '»', '따라', '»', '암복호화를', '»', '하여', '»', '해당', '»', '값이', '»', '일치하면', '»', '카드가', '»', '정상', '»', '카드임을', '»', '알', '»', '수', '»', '있는', '»', '것이다', '.']\n",
      "s : ['IVF', '는', '»', '(', '사', ')', '한국기독학생회의', '»', '영어', '»', '약칭으로', '»', 'Inter-Varsity', '»', 'Christian', '»', 'Fellowship', '의', '»', '약자이다', '.', '»', 'International', '»', 'Fellowship', '»', 'of', '»', 'Evangelical', '»', 'Students', '(', '국제', '»', '칼빈주의', '»', '학생회', ',', 'IFES', ')', '의', '»', '회원단체이다', '.']\n",
      "s : ['619', '년', '»', '5', '월', '»', '23', '일', ',', '»', '양동은', '»', '왕세충', '(', '王', '世', '充', ')', '에게', '»', '선위하고', '»', '황제에서', '»', '물러났으며', '»', '이로써', '»', '왕세충의', '»', '정', '(', '鄭', ')', '이', '»', '건국되고', '»', '수나라는', '»', '완전히', '»', '멸망하였다', '.']\n",
      "s : ['마쓰야마번', '(', ')', '은', '»', '일본', '»', '에도', '»', '시대의', '»', '번', '»', '이름이다', '.']\n",
      "s : ['모든', '»', '잔기를', '»', '잃으면', '»', '게임이', '»', '오버가', '»', '되며', ',', '»', '그', '»', '자리에서', '»', '재도전이', '»', '가능하나', ',', '»', '이전까지', '»', '산적된', '»', '점수는', '»', '0', '점이', '»', '된다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b75d310c7b44f0db9013569860af8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094268794a984c88a5f859d004ca4c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['하지만', '»', '2015', '년', '»', '1', '월', '»', '들어서는', '»', '광명망의', '»', '개인', '»', '이용이', '»', '다시', '»', '허용되었다고', '»', '알려졌음을', '»', '알수가', '»', '있고', '»', '특히', '»', '그리하여', '»', '북한은', '»', '가정집에도', '»', '비대칭', '»', '디지털', '»', '가입자', '»', '회선', '»', '모뎀', '»', '사용을', '»', '다시', '»', '허용', '»', '했음을', '»', '알수가', '»', '있었다', '.']\n",
      "s : ['그래서', '»', '현재', '»', '미래망', '»', '서비스는', '»', '데이터', '»', '가격을', '»', '책정하고', '»', '있으며', '»', '특히', '»', '유료', '»', '서비스로', '»', '추진을', '»', '하고', '»', '있음을', '»', '알수가', '»', '있다는', '»', '것이다', '.']\n",
      "s : ['미나베', '»', '정', '(', ')', '은', '»', '와카야마현', '»', '히다카', '»', '군의', '»', '정이다', '.']\n",
      "s : ['이나미', '»', '정', '(', ')', '은', '»', '와카야마현', '»', '히다카', '»', '군의', '»', '정이다', '.']\n",
      "s : ['히다카가와', '»', '정', '(', ')', '은', '»', '와카야마현', '»', '중부에', '»', '있는', '»', '히다카', '»', '군의', '»', '정이다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3566b6f3df6d44d5bfd36b8c0e289870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291fabe509894fad97c7fdd2ac85ffe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['또한', '»', '최초', '»', '폭발', '»', '당시', '»', '백령도', '»', '지진관측소에서', '»', '관측한', '»', '지진파가', '»', '피로파괴에', '»', '의해', '»', '발생했다고', '»', '보기', '»', '어렵다는', '»', '의견이', '»', '있다', '.']\n",
      "s : ['그러자', '»', '군부는', '»', '이를', '»', '만회해야한다는', '»', '목소리가', '»', '높아졌고', ',', '»', '결국', '»', '4', '군단과', '»', '작전부', ',', '»', '함대', '»', '사령부에', '»', '패배에', '»', '대해', '»', '보복을', '»', '하라는', '»', '지령이', '»', '떨어졌다', '.', '»', '그', '»', '결과가', '»', '천안함', '»', '폭침이라는', '»', '것이다', '.']\n",
      "s : ['연구진은', '»', '수중', '»', '폭발에', '»', '의한', '»', '지진파에서는', '»', '이러한', '»', '조화', '»', '주파수를', '»', '가진', '»', '지진파가', '»', '나타나지', '»', '않으며', ',', '»', '잠수함을', '»', '기하학적', '»', '형태의', '»', '금속', '»', '물체', '(', '튜브형', ')', '라고', '»', '가정하고', '»', '연구를', '»', '진행한', '»', '결과', ',', '»', '튜브형', '»', '금속', '»', '조형물', '»', '축', '»', '진동의', '»', '고유', '»', '진동수', '»', '스펙트럼과', '»', '지진파', '»', '관측', '»', '결과가', '»', \"'\", '만족스럽게', \"'\", '»', '일치하는', '»', '것을', '»', '발견했다고', '»', '설명했다', '.']\n",
      "s : ['국방부장관은', '»', '\"', '오늘날', '»', '지나고', '»', '나서', '»', '다', '»', '이', '»', '사건이', '»', '북한의', '»', '잠수함', '»', '어뢰공격이었구나', '»', '하는', '»', '것을', '»', '아니까', '»', '오늘날', '»', '우리가', '»', '이렇게', '»', '얘기할', '»', '수', '»', '있습니다만', '»', '그', '»', '당시에는', '»', '쉽지', '»', '않았다', '\"', '며', ',', '»', '그것을', '»', '침투나', '»', '도발', '»', '징후로', '»', '인정하지를', '»', '않았다고', '»', '해명했다', '.']\n",
      "s : ['조사단의', '»', '구성원', '»', '문제나', '»', '은폐', '»', '가능성을', '»', '제기했던', '»', '신상철', '(', '서프라이즈', '»', '대표', ')', '에', '»', '대한', '»', '비판도', '»', '존재한다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d42a53277f4430e9c04688d80a5cb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985377f90d64473ead19ce534e7d1639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['같은', '»', '무렵', '»', '류큐에서', '»', '도래한', '»', '신악기', '»', '사피선', '(', '蛇', '皮', '線', ')', '을', '»', '반주하게', '»', '되자', '»', '크게', '»', '비약하고', ',', '»', '더', '»', '나아가', '»', \"'\", '에비스', '»', '돌리기', \"'\", '와', '»', '맺어져', '»', \"'\", '닌교조루리', \"'\", '를', '»', '형성했다', '.']\n",
      "s : ['에야와디', '»', '관구의', '»', '서쪽에는', '»', '아라칸', '»', '산맥이고', '»', '많은', '»', '지역이', '»', '논으로서', ',', '»', '미얀마의', '»', '중요한', '»', '쌀', '»', '생산지로서의', '»', '위치를', '»', '점하고', '»', '있다', '.', '»', '또한', '»', '수많은', '»', '호수가', '»', '있으며', '»', '이라와디', '»', '강에서', '»', '갈라진', '»', '많은', '»', '분류들이', '»', '흐른다', '.']\n",
      "s : ['제주어', '»', '표기를', '»', '할', '»', '수', '»', '있다는', '»', '장점이', '»', '있다', '.']\n",
      "s : ['제재에', '»', '따라', '»', '크게', '»', '시대물', '(', '時', '代', '物', ')', '·', '실재물', '(', '實', '在', '物', ')', '의', '»', '두', '»', '개로', '»', '분류되는데', ',', '»', '내용은', '»', '전일곡', '(', '全', '一', '曲', ')', '의', '»', '주제보다도', '»', '각', '»', '단마다', '»', '반독립적인', '»', '소주제를', '»', '설정한', '»', '의리', '·', '인정의', '»', '전개가', '»', '요점이다', '.']\n",
      "s : [\"'\", '죠루리', \"'\", '의', '»', '연주를', '»', \"'\", '노래부른다', \"'\", '고', '»', '하지', '»', '않고', '»', \"'\", '얘기한다', \"'\", '고', '»', '하는', '»', '의미도', '»', '바로', '»', '여기에', '»', '있다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee0531fdb384e3f907d16e80a81ac3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bbae83cc0f4b8ebc3921a98ee32102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['종목은', '»', '기본', '»', '8', '개', '»', '종목으로', '»', '다시', '»', '돌아왔다', '.', '»', '이', '»', '대회부터', '»', '일본은', '»', '축구', '»', '경기에', '»', '참여하게', '»', '되며', ',', '»', '개최국']\n",
      "s : ['좋아하는', '»', '것', '»', ':', '»', '남', '»', '위로하기', ',', '»', '친구들', ',', '»', '미온의', '»', '부활게임']\n",
      "s : ['\"', '오야시로님의', '»', '환생', '(', 'オ', 'ヤ', 'シ', 'ロ', 'さ', 'ま', 'の', '還', '生', ')', '\"', '이라고', '»', '불리며', '»', '마을', '»', '사람들의', '»', '귀여움과', '»', '숭배의', '»', '대상이', '»', '된다', '.', '»', '이', '»', '때문에', '»', '마을', '»', '사람들은', '»', '\"', '리카쨔마', '(', '梨', '花', 'ち', 'ゃ', 'ま', ')', '\"', '라고', '»', '부른다', '.', '»', '머리카락은', '»', '허리까지', '»', '내려오는', '»', '긴', '»', '생머리로', '»', '파란색이다', '.', '»', '리카는', '»', '자신을', '»', '평소에는', '»', \"'\", '보쿠', '(', 'ボ', 'ク', ')', \"'\", '라고', '»', '부르지만', '»', '어른스러운', '»', '말투로', '»', '말할', '»', '때는', '»', '와타시', '(', '私', ')', '를', '»', '사용한다', '.', '»', \"'\", '미이', '~', '(', 'み', 'い', '~', ')', \"'\", ',', '»', \"'\", '니파', '~', '☆', '(', 'に', 'ぱ', '∼', '☆', ')', \"'\", ',', '»', \"'\", '나노데스', '(', 'な', 'の', 'で', 'す', ')', \"'\", '»', '등의', '»', '말투도', '»', '자주', '»', '사용한다', '.']\n",
      "s : ['공식', '»', '이미지송', '»', 'Dear', '»', 'you', '»', '-Hope-', '(', '후루데', '»', '리카', '»', '테마', ')', '의', '»', '가사를', '»', '보면', '»', '자신이', '»', '구하지', '»', '못한', '»', '이들에', '»', '대한', '»', '그녀의', '»', '안타까운', '»', '심정과', '»', '다시', '»', '한번', '»', '반복해서', '»', '이번에야말로', '»', '이들을', '»', '구하겠다는', '»', '그녀의', '»', '결의를', '»', '담고', '»', '있다', '.']\n",
      "s : ['원작', '»', '미나고로시', '»', '편에서는', '»', '더', '»', '이상', '»', '반복하지', '»', '않고', '»', '이번', '»', '세계에서', '»', '최선을', '»', '다', '»', '하고', '»', '싶은', '»', '리카와', '»', '항상', '»', '옆에서', '»', '다음', '»', '세계를', '»', '기약하고', '»', '기대하지', '»', '말라는', '»', '하뉴', '»', '사이의', '»', '갈등이', '»', '나온다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42889bf4664e4a25a2c9485de11f07df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2046103cb88449a8baadc775d9e3cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['언론에서는', '»', '당일은', '»', '물론', '»', '다음날인', '»', '토요일에도', '»', '정규', '»', '방송을', '»', '중단하고', '»', '보도', '»', '특별', '»', '프로그램을', '»', '편성하여', '»', '이', '»', '사건을', '»', '크게', '»', '다루었다', '.']\n",
      "s : ['그렇기', '»', '때문에', ',', '»', '지금까지', '»', '발화', '»', '원인은', '»', '알', '»', '수', '»', '없는', '»', '상태이다', '.']\n",
      "s : ['자동', '»', '화재', '»', '경보기', '»', '의무', '»', '설치', '»', '기준', '»', '대상이', '»', '확대되고', ',', '»', '소방법', '»', '위반에', '»', '대한', '»', '벌칙을', '»', '강화하고', ',', '»', '방화대상물점검보고제도', '(', ')', '가', '»', '창설되었다', '.']\n",
      "s : ['윈도우', '»', '임베디드', '»', '운영', '»', '체제들은', '»', '하드웨어에', '»', '미리', '»', '로드되는', '»', 'OEM', '으로', '»', '이용이', '»', '가능하며', '»', '일부의', '»', '경우', '»', '볼륨', '»', '라이선스', '»', '고객에게도', '»', '판매되고', '»', '있다', '.']\n",
      "s : ['미국에서는', '»', '근로자의', '»', '단결권을', '»', '보장하는', '»', '헌법상', '»', '명문규정은', '»', '없으나', ',', '»', '연방헌법상', '»', '결사의', '»', '자유에', '»', '따라', '»', '모든', '»', '근로자들의', '»', '단결체에', '»', '단결의', '»', '자유가', '»', '인정되고', '»', '있다고', '»', '볼', '»', '수', '»', '있다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7df9787f804f368118d37224555fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cf181beb724607827f0e0e8eb02d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['2008', '년', '»', '2', '월', '»', '28', '일에', '»', '출시된', '»', '구글', '»', '사이트는', '»', 'HTML', '이나', '»', '웹', '»', '디자인에', '»', '익숙하지', '»', '않은', '»', '사람이라도', '»', '웹', '»', '페이지를', '»', '만들고', '»', '편집할', '»', '수', '»', '있도록', '»', '한다', '.']\n",
      "s : ['구글의', '»', '온라인', '»', '캘린더는', '»', '팀에', '»', '적합하게', '»', '설계된', '»', '통합', '»', '온라인', '»', '공유', '»', '기능을', '»', '갖춘', '»', '캘린더이다', '.', '»', '기업은', '»', '특정', '»', '팀', '»', '캘린더를', '»', '만들고', '»', '이를', '»', '회사', '»', '전체에서', '»', '공유할', '»', '수', '»', '있다', '.', '»', '캘린더를', '»', '다른', '»', '사람에게', '»', '위임하여', '»', '특정', '»', '캘린더', '»', '및', '»', '이벤트를', '»', '관리하도록', '»', '할', '»', '수', '»', '있다', '.']\n",
      "s : ['행아웃', '»', '온에어', '»', '서비스를', '»', '이용하면', '»', '구글', '+', ',', '»', '유튜브', '»', '및', '»', '자신의', '»', '웹사이트에', '»', '생방송을', '»', '스트리밍할', '»', '수', '»', '있다', '.']\n",
      "s : ['또한', '»', '구글은', '»', '행아웃에', '»', 'G', '메일이나', '»', '드라이브와', '»', '같은', '»', '다른', '»', '업무용', '»', '구글', '»', '앱스', '»', '제품과', '»', '동일한', '»', '서비스', '»', '약관을', '»', '적용한다고', '»', '발표했다', '.']\n",
      "s : ['구글의', '»', '소셜', '»', '네트워크', '»', '서비스인', '»', '구글', '+', '는', '»', '2011', '년', '»', '6', '월', '»', '28', '일', '»', '초대', '»', '전용의', '»', '상용', '»', '테스트용으로', '»', '출시되었다', '.', '»', '전문가들은', '»', '구글', '+', '가', '»', '소셜', '»', '네트워크', '»', '서비스', '»', '업계의', '»', '거대', '»', '기업인', '»', '페이스북에', '»', '도전장을', '»', '내밀었다고', '»', '논평했다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783dab2eb6cc4746880432411b0f6f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########  key error : (20, 20) ###########\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2391605d461b472aaf499b63eb611ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['그러나', '»', '당시', '»', '팀', '»', '내의', '»', '스타였던', '»', '쿠벌러', '»', '라슬로와의', '»', '충돌이', '»', '있으면서', '»', '그가', '»', '클럽을', '»', '떠날', '»', '수', '»', '밖에', '»', '없었다', '.']\n",
      "s : ['첫', '»', '시즌에', '»', '코파', '»', '이탈리아를', '»', '우승하였지만', ',', '»', '1969', '년', '»', '칼리아리와의', '»', '원정', '»', '경기', '»', '후', '»', '락커룸에서', '»', '팀의', '»', '중앙공격수였던', '»', '줄리아노', '»', '타촐라가', '»', '사망하면서', '»', '당시', '»', '구단주였던', '»', '알바로', '»', '마르치니와의', '»', '사이가', '»', '틀어지게', '»', '되었다', '.', '»', '결국', '»', '다음', '»', '시즌에', '»', '들쭉날쭉한', '»', '리그', '»', '경기', '»', '결과', '»', '때문에', '»', '마르치니는', '»', '그를', '»', '해임했다', '.']\n",
      "s : ['이', '»', '문구는', '»', '경기장의', '»', '광고판에', '»', '도배되었으며', '»', '선수들로', '»', '하여금', '»', '이를', '»', '구호로', '»', '사용하게', '»', '하였다', '.']\n",
      "s : ['사실상', '»', '수비적이지만', ',', '»', '카테나치오는', '»', '숙련된', '»', '다른', '»', '이탈리아', '»', '팀들이나', '»', '카를', '»', '라판의', '»', '베로우', '»', '전술과는', '»', '약간', '»', '달랐는데', '»', '그가', '»', '풀백을', '(', '특히', '»', '자친토', '»', '파케티', ')', '»', '윙백이', '(', '수비적으론', '»', '스위퍼들이', '»', '지원', ')', '»', '되어', '»', '빠른', '»', '역습', '»', '공격을', '»', '시작했으며', ',', '»', '이탈리아의', '»', '전술의', '»', '주요소가', '»', '되었다', '.', '»', '그러나', '»', '그는', '»', '그의', '»', '팀이', '»', '수비에만', '»', '의지한다고', '»', '말하는', '»', '것을', '»', '거부한다', '.']\n",
      "s : ['이는', '»', '카메룬', ',', '»', '모로코', '(', '2', '회', ')', ',', '»', '튀니지', ',', '»', '코트디부아르', ',', '»', '적도', '»', '기니', '»', '대표팀', '»', '감독을', '»', '맡았던', '»', '앙리', '»', '미셸이나', '»', '네덜란드', ',', '»', '대한민국', ',', '»', '오스트레일리아', ',', '»', '러시아', ',', '»', '터키', '»', '대표팀', '»', '감독을', '»', '맡았던', '»', '거스', '»', '히딩크', ',', '»', '멕시코', ',', '»', '코스타리카', ',', '»', '미국', ',', '»', '나이지리아', ',', '»', '중국', ',', '»', '온두라스', ',', '»', '이라크', '»', '대표팀', '»', '감독을', '»', '맡았던', '»', '보라', '»', '밀루티노비치에', '»', '밀리나', '»', '거스', '»', '히딩크가', '»', '맡은', '»', '네덜란드', '»', '국가', '»', '대표팀을', '»', '제외하고', '»', 'FIFA', '»', '랭킹에', '»', '10', '위권', '»', '이내에', '»', '들어본', '»', '적이', '»', '있는', '»', '나라가', '»', '없다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1c80fe461742d49cb31707f0c02451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045348b262af4faf8f6f66f1d97d4fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['연기에', '»', '대해서는', ',', '»', '\"', '혼자서는', '»', '찾을', '»', '수', '»', '없는', '»', '자신을', '»', '알게되거나', ',', '»', '자신과는', '»', '다른', '»', '역할을', '»', '할', '»', '수', '»', '있다는', '»', '것이', '»', '재밌다', '\"', '라고', '»', '말했다', '.', '»', '목표하는', '»', '여배우로서는', '»', '다케우치', '»', '유코와', '»', '카호를', '»', '인터뷰에서', '»', '꼽았다', '.', '»', '영화', '»', '\"', '모래시계', '\"', '에서는', ',', '»', '카호와', '»', '함께', '»', '연기했다', '.', '»', '이', '»', '작품에서는', '»', '시마네', '»', '사투리로', '»', '연기하고', '»', '있다', '.']\n",
      "s : ['초등학교', '»', '6', '학년', '»', '때', '»', '사무소', '»', '입소', '.']\n",
      "s : ['2015', '년', '»', '5', '월', ',', '»', '2015', '년', '»', '6', '월호로', '»', 'Seventeen', '»', '전속', '»', '모델을', '»', '졸업하는', '»', '것이', '»', '발표되었다', '.']\n",
      "s : ['2015', '년', ',', '»', '《', 'Seventeen', '》', '»', '전속', '»', '모델을', '»', '졸업했다', '.', '»', '10', '월', ',', '»', '드라마', '»', '《', '테디', '»', '고', '!', '》', '로', '»', '연속', '»', '드라마', '»', '첫', '»', '주연을', '»', '맡았다', '.']\n",
      "s : ['요들', '(', 'Yodel', ')', '은', '»', '알프스', '»', '산맥', ',', '»', '티롤', '»', '지방에서', '»', '불리는', '»', '독특한', '»', '음악', '»', '장르이다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56db08941b204f24881e7795aa9d115f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########  key error : (1, 20) ###########\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ce99dd074a4674a35a642fa62e9cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : [\"'\", '이', '»', '달의', '»', '가수전', \"'\", '»', '1', '위', '»', '가수는', '»', '가왕전에', '»', '진출하기', '»', '위해', '»', '명예', '»', '하차를', '»', '하고', ',', '»', \"'\", '고별', '»', '가수전', \"'\", '에서', '»', '최하위', '»', '가수는', '»', '탈락을', '»', '한다', '.', '»', '즉', '»', '매달', '»', '2', '명의', '»', '가수가', '»', '프로그램에서', '»', '하차하는', '»', '것이다', '.']\n",
      "s : ['모라바슬레스코', '»', '주', '(', ')', '는', '»', '체코', '»', '모라바', '»', '지방', '»', '북동부와', '»', '체코령', '»', '슬레스코', '»', '대부분', '»', '지역에', '»', '위치한', '»', '주로', ',', '»', '주도는', '»', '오스트라바이며', '»', '면적은', '»', '5', ',', '445km', ',', '»', '인구는', '»', '1', ',', '260', ',', '503', '명', '(', '2011', '년', '»', '3', '월', '»', '기준', ')', ',', '»', '인구', '»', '밀도는', '»', '230', '명', '/', 'km', '이다', '.', '»', '5', '개', '»', '행정구를', '»', '관할한다', '.']\n",
      "s : ['남모라바', '»', '주', '(', ')', '는', '»', '체코', '»', '모라바', '»', '지방', '»', '남서부에', '»', '위치한', '»', '주로', ',', '»', '주도는', '»', '브르노이며', '»', '면적은', '»', '7', ',', '196.5km', ',', '»', '인구는', '»', '1', ',', '196', ',', '113', '명', '(', '2011', '년', '»', '3', '월', '»', '기준', ')', ',', '»', '인구', '»', '밀도는', '»', '166', '명', '/', 'km', '이다', '.', '»', '7', '개', '»', '행정구를', '»', '관할한다', '.']\n",
      "s : ['1994', '년에는', '»', '3', '월', '»', '31', '일에', '»', '제', '1', '호', '»', '태풍', '»', '오웬이', '»', '발생한', '»', '것을', '»', '시작으로', ',', '»', '연말까지', '»', '총', '»', '36', '개의', '»', '태풍이', '»', '발생하였다', '.', '»', '평균적으로', '»', '1', '년', '»', '동안', '»', '태풍', '»', '발생', '»', '개수가', '»', '26.7', '개인', '»', '것과', '»', '비교하면', '»', '매우', '»', '높은', '»', '수치이다', '.']\n",
      "s : ['인라인', '»', '함수', '(', 'inline', '»', 'function', ')', '는', '»', '여러', '»', '버전의', '»', 'C', '와', '»', 'C', '+', '+', '»', '프로그래밍', '»', '언어에서', '»', '컴파일러가', '»', '인라인', '»', '확장', '»', '수행을', '»', '요청', '»', '받는', '»', '함수이다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46ddba5ff3440e1adf7cfb0155ef08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44db8d77dda44dcb7da289910c1de65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['엘리자베스', '(', 'Elizabeth', ')', '는', '»', '뉴저지주의', '»', '도시로', ',', '»', '인구는', '»', '124', ',', '969', '명이다', '.']\n",
      "s : ['취미는', '»', '독서', ',', '»', '작사', ',', '»', '음악', '»', '감상', ',', '»', '노래', ',', '»', '그림', '»', '그리기', ',', '»', '특기는', '»', '서예', ',', '»', '장거리', '»', '달리기', ',', '»', '아와오도리', '(', '남자', '»', '춤', ')', '이다', '.', '»', '일본어', '»', '문장', '»', '능력', '»', '검정', '»', '5', '급', ',', '»', '영어', '»', '검정', '»', '준', '»', '2', '급의', '»', '자격을', '»', '보유하고', '»', '있다', '.']\n",
      "s : ['스테판', '»', '피에르', '»', '이브', '»', '기바르쉬', '(', 'St', 'é', 'phane', '»', 'Pierre', '»', 'Yves', '»', 'Guivarc', \"'\", 'h', ',', '»', '1970', '년', '»', '9', '월', '»', '6', '일', '~', ')', '는', '»', '공격수로', '»', '활동했던', '»', '프랑스의', '»', '전', '»', '축구선수이다', '.', '»', '자국에서', '»', '열린', '»', '1998', '년', '»', 'FIFA', '»', '월드컵에서', '»', '우승을', '»', '거둔', '»', '프랑스', '»', '대표팀에', '»', '속했다', '.']\n",
      "s : ['1960', '년대부터', '»', '1980', '년대까지', '»', '세계의', '»', '주요', '»', '항공사들이', '»', '많이', '»', '이용했으나', '»', '1990', '년대', '»', '들어', '»', '두바이', '»', '국제공항이', '»', '각광', '»', '받으면서', '»', '이용량이', '»', '다소', '»', '줄어들었다', '.']\n",
      "s : ['〈', '초', 'HAPPY', '»', 'SONG', '»', '(', '싱글', '»', 'Ver.', ')', '〉', '은', '»', '편곡을', '»', '변경하고', '»', '있다', '.', '»', '게다가', '»', '℃', '-ute', '측의', '»', '보컬', '»', '파트는', '»', '오리지널의', '»', '〈', '행복의', '»', '도중', '〉', '보다도', '»', '밝아진', '»', '목소리와', '»', '가창법으로', '»', '다시', '»', '녹음한', '»', '것이다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419ada270cbc491487534569232bafe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dcc6a376c74c04a9f3124ddd95b934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['대한민국의', '»', '팝업', '»', '기업', '»', '인', '»', 'L.S', '»', 'Holdings', '는', '»', '3', '번째', '»', '프로젝트인', '»', '린치', '»', '코리아를', '»', '2010', '년에', '»', '설립하였다', '.', '»', '당시', '»', '대한민국에', '»', '유행처럼', '»', '번지던', '»', '온라인', '»', '쇼핑몰들을', '»', '상대하는', '»', '온라인', '»', '마케팅', '»', '및', '»', '경영', '»', '컨설턴트', '»', '업체로는', '»', '최초였다', '.']\n",
      "s : ['태어난', '»', '해는', '»', '알', '»', '수', '»', '없으나', ',', '»', '아버지인', '»', '소가노', '»', '에미시', '(', '蘇', '我', '蝦', '夷', ')', '가', '»', '586', '년', '»', '무렵에', '»', '태어났다고', '»', '하는', '»', '것으로', '»', '보아', '»', '대략', '»', '600', '년', '610', '년', '»', '무렵으로', '»', '추정한다', '.']\n",
      "s : ['이로서', '»', '명실상부한', '»', '소가', '»', '씨', '»', '가독', '(', '家', '督', ')', '을', '»', '이어받았지만', ',', '»', '이', '»', '무렵', '»', '쇼토쿠', '»', '태자', '»', '이후', '»', '왕실', '»', '주위에는', '»', '국정을', '»', '오키미', '(', '大', '王', ')', '»', '중심으로', '»', '개혁하려는', '»', '기운이', '»', '나날이', '»', '강해져가고', '»', '있었고', ',', '»', '이루카는', '»', '이러한', '»', '움직임을', '»', '억누르고', '»', '소가', '»', '씨와', '»', '혈연이', '»', '강한', '»', '후루히토노', '»', '오에', '(', '古', '人', '大', '兄', ')', '를', '»', '오키미로', '»', '추대하고자', '»', '했다', '.']\n",
      "s : ['그러나', '»', '이같은', '»', '이루카의', '»', '천하는', '»', '오래가지', '»', '못했다', '.']\n",
      "s : ['《', '일본서기', '》', '는', '»', '이루카의', '»', '사적을', '»', '소가', '»', '씨의', '»', '월권행위로', '»', '무리하게', '»', '후루히토노오에를', '»', '오키미로', '»', '추대하기', '»', '위한', '»', '준비작업이었다고', '»', '비판하지만', ',', '»', '소가', '»', '씨는', '»', '원래', '»', '우마코의', '»', '대부터', '»', '대륙의', '»', '문물을', '»', '적극', '»', '수용하는데', '»', '힘썼던', '»', '개혁파', '»', '선두로서', '»', '당이나', '»', '백제', '»', '등', '»', '당시의', '»', '국가', '»', '상황에', '»', '대응하기', '»', '위한', '»', '움직임이었다는', '»', '의견도', '»', '있다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7c68729d534517979a76cb167d67f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e455af2401040aa87b24442f3deaab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['경주', '»', '망덕사지', '(', '慶', '州', '»', '望', '德', '寺', '址', ')', '는', ',', '»', '경상북도', '»', '경주시', '»', '낭산의', '»', '기슭에', '»', '있는', '»', '절터이다', '.', '»', '1963', '년', '»', '1', '월', '»', '21', '일', '»', '대한민국의', '»', '사적', '»', '제', '7', '호로', '»', '지정되었다', '.']\n",
      "s : ['《', '삼국사기', '》', '»', '및', '»', '《', '삼국유사', '》', '에는', '»', '경덕왕', '(', '景', '德', '王', ')', '»', '14', '년', '(', '755', '년', ')', '»', '망덕사의', '»', '탑이', '»', '흔들렸다는', '»', '기록이', '»', '있는데', ',', '»', '공교롭게도', '»', '그', '»', '해에', '»', '당에서', '»', '안사의', '»', '난이', '»', '일어나자', '»', '당시', '»', '신라', '»', '사람들은', '»', '\"', '당을', '»', '위해', '»', '지은', '»', '절이니', '»', '그에', '»', '응한', '»', '것이다', '\"', '라고', '»', '말했다고', '»', '한다', '.']\n",
      "s : ['목탑의', '»', '터는', '»', '논', '»', '한가운데', '»', '흙으로', '»', '쌓은', '»', '단의', '»', '흔적이', '»', '확인되는데', ',', '»', '13', '층으로', '»', '되어', '»', '있었던', '»', '두', '»', '탑', '»', '중', '»', '서탑은', '»', '나무와', '»', '흙에', '»', '매몰되어', '»', '동탑에', '»', '비해', '»', '그', '»', '훼손', '»', '상태가', '»', '더욱', '»', '심각하다', '.', '»', '동탑은', '»', '북면', '»', '길이', '»', '123cm', ',', '»', '동면', '»', '길이', '»', '127cm', '로', '»', '흙으로', '»', '쌓은', '»', '기단', '»', '높이는', '»', '120cm', '»', '정도이다', '.']\n",
      "s : ['팔각형', '»', '한', '»', '변', '»', '길이는', '»', '동탑이', '»', '60cm', ',', '»', '서탑이', '»', '동서남북', '»', '60cm', '에', '»', '북동', ',', '»', '북서', ',', '»', '남동', ',', '»', '남서', '»', '50cm', '이며', ',', '»', '사리공의', '»', '네모', '»', '모양으로', '»', '된', '»', '구멍은', '»', '동탑이', '»', '가로세로', '»', '25cm', ',', '»', '서탑은', '»', '23cm', '이다', '(', '서탑', '»', '사리공의', '»', '경우', '»', '사천왕사', '»', '목탑의', '»', '크기와도', '»', '비슷', ')', '.', '»', '탑의', '»', '바닥에는', '»', '무늬', '»', '없는', '»', '전돌을', '»', '깔았던', '»', '것으로', '»', '확인되었다', '.']\n",
      "s : ['경주시의', '»', '개발로', '»', '대부분', '»', '파손되고', '»', '지금은', '»', '일부에', '»', '흔적만', '»', '남아있다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11ae10195c14b259c993fa52f78ef21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########  key error : (13, 13) ###########\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727e25f19c3d43e3a618b7604cb2403b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['근처에', '»', '죽변항이', '»', '인접해', '»', '있어', '»', '관광객', '»', '이용자들이', '»', '많은', '»', '편인데', '»', '버스', '»', '정차지가', '»', '협소하여', '»', '불편했으나', '»', '최근에는', '»', '정류장', '»', '일대', '»', '도로가', '»', '왕복', '»', '2', '차선에서', '»', '4', '차선으로', '»', '확장된', '»', '상태다', '.', '»', '또한', '»', '터미널', '»', '건물도', '»', '2009', '년', '~', '2011', '년', '»', '사이에', '»', '리모델링되었다', '.']\n",
      "s : ['ISO', '/', 'TC', '»', '37', '은', '»', '소위', '»', '\"', '수평적', '»', '위원회', '\"', '로서', ',', '»', '다른', '»', '모든', '»', '기술위원회들이', '»', '그들의', '»', '전문용어와', '»', '관련된', '»', '문제들을', '»', '다루는', '»', '표준들을', '»', '개발하는', '»', '데', '»', '필요한', '»', '지침들을', '»', '제공해', '»', '준다', '.', '»', '그러나', '»', 'ISO', '/', 'TC', '»', '37', '에서', '»', '개발한', '»', '표준들은', '»', 'ISO', '에', '»', '국한되지', '»', '않는다', '.']\n",
      "s : ['ISO', '/', 'TC', '»', '37', '»', '은', '»', '아래와', '»', '관련된', '»', '국제표준을', '»', '개발한다', ':']\n",
      "s : ['전문용어', '»', '표준화의', '»', '시작은', '»', 'IEC', '»', '(', 'International', '»', 'Electrotechnical', '»', 'Commission', ',', '»', '1906', '년', '»', '설립', ')', '»', '와', '»', 'ISO', '»', '(', 'International', '»', 'Organization', '»', 'for', '»', 'Standardization', ',', '»', '1946', '년', '»', '설립', ')', '의', '»', '표준화', '»', '노력과', '»', '밀접하게', '»', '관련되어', '»', '있다', '.']\n",
      "s : ['오늘날', ',', '»', '전문용어', '»', '표준화는', '»', '다음과', '»', '같은', '»', '두', '»', '개의', '»', '활동으로', '»', '세분할', '»', '수', '»', '있다', ':']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6097d074147e4818bc642b968be9a89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31153678198849c9b0cd95f77d0a11e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['아메리카짧은꼬리땃쥐류는', '»', '붉은이땃쥐아과', '»', '아메리카짧은꼬리땃쥐속', '(', '\"', 'Blarina', '\"', ')', '에', '»', '속하는', '»', '포유류의', '»', '총칭으로', '»', '비교적', '»', '큰', '»', '땃쥐류', '»', '분류군의', '»', '하나이다', '.', '»', '아메리카에서', '»', '발견되며', ',', '»', '비교적', '»', '짧은', '»', '꼬리와', '»', '32', '개의', '»', '이를', '»', '갖고', '»', '있다', '.']\n",
      "s : ['또한', '»', '이', '»', '시기의', '»', '부인', '(', '夫', '人', ')', '은', '»', '단지', '»', '남의', '»', '처를', '»', '높여', '»', '부르는', '»', '단어가', '»', '아니라', '»', '엄연한', '»', '봉작명으로', '»', '추정할', '»', '수도', '»', '있는데', ',', '»', '초기의', '»', '신라에선', '»', '왕의', '»', '모친과', '»', '왕비를', '»', '부인으로', '»', '봉하였고', ',', '»', '고구려에선', '»', '왕의', '»', '측실을', '»', '소후', '(', '小', '后', ')', '»', '혹은', '»', '부인으로', '»', '봉하였으며', ',', '»', '백제에선', '»', '15', '대', '»', '침류왕의', '»', '어머니가', '»', '아마부인으로', '»', '봉해졌던', '»', '만큼', '»', '묘비나', '»', '기록에', '»', '남은', '»', '\"', '○', '○', '부인', '\"', '이라는', '»', '호칭이', '»', '관작일', '»', '가능성도', '»', '존재한다', '.']\n",
      "s : ['이후', '»', '여러', '»', '왕을', '»', '거치며', '»', '대상이', '»', '확대되었는데', ',', '»', '공민왕', '»', '때에', '»', '이르러선', '»', '영역이', '»', '모호해져', '»', '침모와', '»', '내료', '(', '內', '僚', ')', '의', '»', '딸을', '»', '옹주와', '»', '택주로', '»', '봉하기에', '»', '이르렀고', '»', '이는', '»', '우왕', '»', '때에도', '»', '계속되어', '»', '대신들의', '»', '원성이', '»', '높았다', '.']\n",
      "s : ['이로', '»', '인해', '»', '세', '»', '아들을', '»', '과거에', '»', '급제시킨', '»', '공으로', '»', '국대부인에', '»', '오른', '»', '여성도', '»', '존재했다', '.']\n",
      "s : ['태조', '»', '5', '년', ',', '»', '문무대신의', '»', '처의', '»', '봉작을', '»', '개정하여', '»', '1', '품', '»', '대신의', '»', '처는', '»', '군부인', '(', '郡', '夫', '人', ')', ',', '»', '2', '품은', '»', '현부인', '(', '縣', '夫', '人', ')', ',', '»', '정', '3', '품으로', '»', '성균', '»', '대사성', '(', '成', '均', '大', '司', '成', ')', '»', '이상의', '»', '처는', '»', '숙인', '(', '淑', '人', ')', ',', '»', '나머지', '»', '3', '품은', '»', '영인', '(', '令', '人', ')', ',', '»', '4', '품은', '»', '공인', '(', '恭', '人', ')', ',', '»', '5', '품은', '»', '의인', '(', '宜', '人', ')', ',', '»', '6', '품은', '»', '안인', '(', '安', '人', ')', ',', '»', '7', '품', '»', '이하', '»', '참외', '(', '參', '外', ')', '는', '»', '유인', '(', '孺', '人', ')', '으로', '»', '삼았는데', ',', '»', '가장이나', '»', '아들에게', '»', '공이', '»', '있어', '»', '특별히', '»', '봉작받는', '»', '자는', '»', '이', '»', '제한을', '»', '두지', '»', '않았으며', ',', '»', '반드시', '»', '처녀로서', '»', '정처가', '»', '된', '»', '자여야', '»', '하고', '»', '만일', '»', '개가', '(', '=', '재혼', ')', '를', '»', '할', '»', '경우엔', '»', '봉작을', '»', '추탈한다는', '»', '예외', '»', '조건을', '»', '더하였다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55992e7804d74303b2e2524fc452c114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bca4e895eb43f8a73c39af8269e14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['그는', '»', '인터뷰에서', '»', '\"', '지판상의', '»', '운지의', '»', '이미지에서', '»', '새로운', '»', '음계를', '»', '발상한다', '\"', '고', '»', '말한', '»', '적이', '»', '있고', '»', '이는', '»', '그의', '»', '음악적', '»', '발상의', '»', '특징과', '»', '독자성을', '»', '나타내는', '»', '것이다', '.']\n",
      "s : ['《', '남자사용설명서', '》', '는', '»', '2013', '년에', '»', '개봉한', '»', '대한민국의', '»', '영화이다', '.']\n",
      "s : ['《', '헤드', '》', '는', '»', '2011', '년에', '»', '개봉한', '»', '대한민국의', '»', '영화이다', '.']\n",
      "s : ['양산', '»', '통도사', '»', '명부전', '»', '지장보살도', '·', '시왕도', '·', '사자도', '(', '梁', '山', '»', '通', '度', '寺', '»', '冥', '府', '殿', '»', '地', '藏', '菩', '薩', '圖', '·', '十', '王', '圖', '·', '使', '者', '圖', ')', '는', '»', '경상남도', '»', '양산시', ',', '»', '통도사에', '»', '있는', '»', '조선시대의', '»', '불화이다', '.', '»', '2014', '년', '»', '3', '월', '»', '20', '일', '»', '경상남도', '»', '유형문화재', '»', '제', '549', '호로', '»', '지정되었다', '.']\n",
      "s : ['양산', '»', '통도사', '»', '오방제위도', '(', '梁', '山', '»', '通', '度', '寺', '»', '五', '方', '帝', '位', '圖', ')', '는', '»', '경상남도', '»', '양산시', ',', '»', '통도사에', '»', '있는', '»', '조선시대의', '»', '불화이다', '.', '»', '2014', '년', '»', '3', '월', '»', '20', '일', '»', '경상남도', '»', '유형문화재', '»', '제', '550', '호로', '»', '지정되었다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653c174486be4e59863af9ff85f94f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1180c58a24cb40af9cacc2cd1fad1a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['북쪽의', '»', '시나르카', '»', '산과', '»', '이어져', '»', '있다', '.']\n",
      "s : ['2015', '년', '»', '3', '월', '»', '9', '일', '»', '미국', '»', '샌프란시스코', '»', '에바', '»', '부에나', '»', '센터에서', '»', '열린', '»', '공식', '»', '행사에서', '»', '애플', '»', '워치에', '»', '대한', '»', '정보를', '»', '추가적으로', '»', '발표했다', '.', '»', '2015', '년', '»', '4', '월', '»', '24', '일에', '»', '1', '차', '»', '출시국에서', '»', '판매하며', ',', '»', '대한민국의', '»', '애플워치', '»', '출시일은', '»', '6', '월', '»', '26', '일이다', '.']\n",
      "s : ['시리즈', '2', '는', '»', '듀얼', '»', '코어', '»', '애플', '»', 'S2', '»', '프로세서', ',', '»', '50m', '»', '방수', '»', '기능', ',', '»', '두', '»', '배', '»', '이상의', '»', '밝은', '»', '디스플레이', '»', '및', '»', 'GPS', '»', '수신기를', '»', '갖추고', '»', '있다', '.']\n",
      "s : ['조선', '»', '효종', '(', '재위', '»', '1649', '∼', '1659', ')', '»', '때', '»', '병조판서를', '»', '지낸', '»', '동춘당', '»', '송준길', '»', '선생이', '»', '관직을', '»', '물러난', '»', '후', '»', '거처하던', '»', '곳으로', '»', '동춘당', '»', '뒤쪽에', '»', '있다', '.', '»', '동춘당은', '»', '조선시대', '»', '대표적', '»', '별당', '»', '건축물로', '»', '보물', '»', '제', '209', '호로', '»', '지정되어', '»', '있다', '.']\n",
      "s : ['대청마루의', '»', '오른쪽에는', '»', '각', '»', '1', '칸씩', '»', '건너방과', '»', '웃방', ',', '»', '부엌', ',', '»', '반찬을', '»', '두는', '»', '찬방', ',', '»', '그리고', '»', '행랑방이', '»', '붙어', '»', '있어', '»', '전체적으로', '»', 'ㄷ자를', '»', '이룬다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b7e3d34e9d40f3b9ab474a1542f842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b1b690603d4d91872287225177b5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['2007', '년', '»', '7', '월', '»', '1', '일', '»', '리저브', '»', '리그', '»', '요코하마', '»', 'F.', '»', '마리노스와의', '»', '경기에서', '»', '소장을', '»', '다치는', '»', '큰', '»', '부상을', '»', '입어', '»', '한동안', '»', '경기에', '»', '나서지', '»', '못하였다', '.']\n",
      "s : ['2018', '년', '»', '1', '월', '»', '4', '일에', '»', '울산', '»', '현대로', '»', '1', '년', '»', '임대', '»', '이적하였지만', ',', '»', 'K', '리그', '»', '적응에', '»', '실패하여', '»', '9', '경기', '»', '2', '골에', '»', '그쳤고', ',', '»', '원', '»', '소속팀인', '»', '사간', '»', '도스의', '»', '요청으로', '»', 'K', '리그', '»', '진출', '»', '6', '개월만에', '»', 'J', '리그에', '»', '임대', '»', '복귀하였다', '.']\n",
      "s : ['주거공유는', '»', '주택을', '»', '가족', '»', '이외의', '»', '사람과', '»', '공유하는', '»', '것을', '»', '말한다', '.']\n",
      "s : ['홈셰어링은', '»', '모든', '»', '연령의', '»', '룸메이트에게', '»', '좋은', '»', '선택이', '»', '될', '»', '수', '»', '있지만', ',', '»', '독립을', '»', '준비하는', '»', '노인에게', '»', '이점이', '»', '있다', '.', '»', '대부분의', '»', '경우', ',', '»', '노인들이', '»', '요양시설로', '»', '보내지는', '»', '것을', '»', '피하거나', '»', '미루기', '»', '위해', '»', '동거인을', '»', '가질', '»', '수', '»', '있다', '.']\n",
      "s : ['동거인은', '»', '넘어지거나', '»', '비상시에', '»', '빠르게', '»', '대처', '»', '하지', '»', '못하는', '»', '노인들의', '»', '안전', '»', '조치를', '»', '제공한다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeaee07965f4605b71832cdedfdaa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2d04cec28e4d94b8d06820dc53568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['죽은', '»', '마법사의', '»', '도시는', '»', '만화가', '»', '김칸비와', '»', '팀', '»', '겟네임가', '»', '네이버', '»', '웹툰에서', '»', '연재하는', '»', '웹툰이다', '.', '»', '2011', '년', '»', '12', '월', '»', '6', '일', '»', '첫', '»', '연재를', '»', '시작했다', '.']\n",
      "s : ['2013', '년', '»', '마법사', '»', '대학살', '»', '사건', '»', '당시', '»', '이카루스와의', '»', '싸움에서', '»', '패해', '»', '죽게된다', '.']\n",
      "s : ['도사', '.', '»', '원래', '»', '시간', '»', '마법을', '»', '가지고', '»', '있었으나', ',', '»', '세명의', '»', '현자에', '»', '의해', '»', '이를', '»', '빼앗기고', '»', '세명의', '»', '현자', '»', '중', '»', '한명인', '»', '미스터', '»', '홍을', '»', '따라가', '»', '한국에', '»', '정착해', '»', '새롭게', '»', '삶을', '»', '시작한다', '.']\n",
      "s : ['오자와', '»', '아리', '(', '小', '澤', '»', '亜', '李', ',', '»', '1992', '년', '»', '8', '월', '»', '10', '일', ')', '는', '»', '일본', '»', '도쿄도', '»', '출신의', '»', '여성', '»', '성우이다', '.']\n",
      "s : ['취미는', '»', '가지고', '»', '있지', '»', '않으나', ',', '»', '일러스트가', '»', '특기라고', '»', '말했다', '.', '»', '소라라는', '»', '이름의', '»', '개를', '»', '키우고', '»', '있다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f255327a08004849af06dab6a5e6901b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########  key error : (19, 20) ###########\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574f0213fd7e4c24b3a626340b80243d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['출전국이', '»', '24', '개국에서', '»', '32', '개국으로', '»', '늘어나면서', '»', '대륙별', '»', '선수권', '»', '대회가', '»', '아닌', '»', '홈', '»', '앤', '»', '어웨이', '»', '방식으로', '»', '지역', '»', '예선을', '»', '치르게', '»', '되었다', '.']\n",
      "s : ['럭키금성', '»', '(', '현', '»', 'FC', '»', '서울', ')', '에서', '»', '1984-1985', '»', '시즌', '»', '동안', '»', '미드필더로', '»', '활약하며', '»', '정규리그', '»', '11', '경기', '»', '출전', '»', '1', '득점', ',', '»', '1', '도움의', '»', '기록을', '»', '남겼다', '.']\n",
      "s : ['세븐나이츠', '(', ')', '는', '»', '넷마블', '»', '넥서스에서', '»', '개발한', '»', '모바일', '»', '플랫폼을', '»', '기반으로', '»', '하는', '»', '롤플레잉', '»', '게임이다', '.', '»', '대한민국의', '»', '유저는', '»', '카카오계정과', ',', '»', '그', '»', '외', '»', '국가의', '»', '유저는', '»', '구글', '»', '계정과', '»', '연동하여', '»', '플레이할', '»', '수', '»', '있다', '.']\n",
      "s : ['기존의', '»', '카드', '»', '수집', '»', '게임', '»', '등에', '»', '존재하는', ',', '»', '카드', '»', '강화', '»', '등을', '»', '통해', '»', '조건에', '»', '부합한', '»', '카드를', '»', '가지고', '»', '있다면', '»', '영웅을', '»', '강화시킬', '»', '수', '»', '있다', '.']\n",
      "s : ['재화', '»', '던전은', '»', '열쇠를', '»', '소모해', '»', '입장하여', '»', '하루', '»', '한번', '»', '클리어가', '»', '가능한', '»', '던전이다', '.', '»', '희귀', '»', '영웅', '»', '카드와', '»', '영웅', '»', '강화에', '»', '유용한', '»', '것들을', '»', '획득할', '»', '수', '»', '있다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfd2f6597c44afd9154cedfd0e20b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64face45c75d4f3c919c8ddd54aa5794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['솔로후브는', '»', '2005', '년', '»', '세계', '»', '선수권', '»', '대회', '»', '400m', '»', '계주에서', '»', '동메달을', '»', '획득했다', '.']\n",
      "s : ['마숀다', '(', 'Mashonda', ',', '»', '1979', '년', '»', '1', '월', '»', '9', '일', '»', '~', '»', ')', '는', '»', '할렘', '»', '출신', '»', '미국의', '»', 'R', '&', 'B', '»', '싱어송라이터이다', '.']\n",
      "s : ['2015', '년', '»', '3', '백만', '»', '달러', '»', '이상을', '»', '벌면서', ',', '»', '2016', '년', '»', '포브스지', '»', '선정', '»', \"'\", '세계에서', '»', '수익이', '»', '많은', '»', '유튜브', '»', '스타', \"'\", '»', '리스트에서', '»', '3', '위를', '»', '했다', '.']\n",
      "s : ['성충의', '»', '눈', '»', '색깔은', '»', '붉은', '»', '색이고', '»', '몸', '»', '색깔은', '»', '노란색이다', '.', '»', '성충은', '»', '온실가루이보다', '»', '작으나', '»', '크기로', '»', '구분은', '»', '어렵다', '.', '»', '몸의', '»', '길이가', '»', '0.8mm', '»', '정도이며', ',', '»', '몸의', '»', '색깔은', '»', '짙은', '»', '황색이다', '.', '»', '잎에', '»', '앉아', '»', '있을때는', '»', '날개를', '»', '편', '»', '선이', '»', '잎과', '»', '45', '°', '의', '»', '각도를', '»', '이룬다', '.']\n",
      "s : ['제', '26', '회', '»', '아시아', '»', '아마추어', '»', '복싱', '»', '선수권', '»', '대회는', '»', '2011', '년', '»', '8', '월', '»', '5', '일부터', '»', '8', '월', '»', '12', '일까지', '»', '대한민국', '»', '인천에서', '»', '열렸다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88eaa29a10849bcae4cfbe7d771fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########  key error : (0, 1) ###########\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287c2c76852c4fca82731e553cbd9a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['지역', '»', '대관구지휘자는', '»', '정당', '»', '행정', '»', '뿐', '»', '아니라', '»', '정부', '»', '직책에도', '»', '관여하여', '»', '선전', '»', '감시', '»', '등', '»', '다양한', '»', '작전을', '»', '수행했으며', ',', '»', '1944', '년', '»', '9', '월', '»', '이후에는', '»', '국민돌격대', '»', '소집과', '»', '각', '»', '대관구', '»', '방어작전', '»', '역할도', '»', '맡았다', '.']\n",
      "s : ['조성원의', '»', '아내인', '»', '김해란은', '»', '현재', '»', '대전', '»', 'KGC', '인삼공사', '»', '배구단', '»', '소속의', '»', '배구', '»', '선수이다', '.']\n",
      "s : ['모리', '»', '시오리', '»', '(', 'も', 'り', 'し', 'お', 'り', ')', '(', ')', '는', '»', '일본', '»', '여성', '»', '아이돌', '»', '그룹인', '»', '파스포의', '»', '맴버이다', '.']\n",
      "s : ['〈', 'Mr.Wednesday', '〉', '(', '미스터', '.', '웬스데이', ')', '는', '»', '2016', '년', '»', '2', '월', '»', '24', '일에', '»', '발매된', '»', '파스포', '☆', '의', '»', '메이저', '»', '데뷔', '»', '14', '번째', '»', '싱글이다', '.']\n",
      "s : ['타위', '»', '슬리', '(', 'Tawi', '»', 'Sli', ')', '는', '»', '말레이시아의', '»', '정치인으로', ',', '»', '사라왁주의', '»', '총리를', '»', '지낸', '»', '인물이다', '.', '»', '1966', '년', '»', '스테픈', '»', '칼롱', '»', '닝칸의', '»', '축출', '»', '이후', '»', '총리로', '»', '취임했으며', ',', '»', '1970', '년', '»', '사임했다', '.', '»', '1974', '년', '»', '정계에서', '»', '완전', '»', '은퇴했고', ',', '»', '이후', '»', '개인', '»', '사업에', '»', '집중하다가', '»', '1987', '년', '»', '별세했다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323b47fef84f438cbf3fff51a09d822b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14719dfa90a64f24a0cd38d7b7038370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['이후', '»', '칼론', ',', '»', '브리엔을', '»', '기용하였으나', ',', '»', '재정은', '»', '악화될', '»', '뿐', '»', '개혁은', '»', '특권', '»', '신분의', '»', '반항으로', '»', '실현할', '»', '수가', '»', '없었고', ',', '»', '1788', '년', '»', '삼부회의', '»', '소집을', '»', '결정', ',', '»', '재차', '»', '네케르를', '»', '기용하였다', '.']\n",
      "s : ['나폴레옹은', '»', '뤼네빌', ',', '»', '아미앵', '»', '조약의', '»', '체결로', '»', '평화를', '»', '회복하고', ',', '»', '종교협약', ',', '»', '나폴레옹', '»', '법전', '»', '등으로써', '»', '프랑스', '»', '국내', '»', '정치를', '»', '안정시키고', ',', '»', '1804', '년', '»', '5', '월', '»', '황제가', '»', '되어', '»', '12', '월에', '»', '대관식을', '»', '가졌다', '.']\n",
      "s : ['17', '세기', '»', '말의', '»', '카를로비츠', '»', '조약에', '»', '의해서', '»', '표면화된', '»', '오스만', '»', '제국의', '»', '쇠운은', '»', '18', '세기가', '»', '되자', '»', '유럽', '»', '열강', ',', '»', '특히', '»', '오스트리아와', '»', '러시아의', '»', '압력에', '»', '의해서', '»', '한층', '»', '심해진다', '.', '»', '18', '세기', '»', '초에', '»', '즉위한', '»', '아흐메트', '»', '3', '세', '(', '재위', '»', '1703', '»', '1730', ')', '의', '»', '치세', '»', '전기에는', '»', '러시아', '»', '및', '»', '오스트리아와', '»', '전쟁을', '»', '치렀다', '.']\n",
      "s : ['사파비', '»', '왕조의', '»', '번영기가', '»', '지나자', ',', '»', '이란은', '»', '20', '세기까지', '»', '긴', '»', '쇠퇴의', '»', '시대로', '»', '들어갔다', '.', '»', '18', '세기는', '»', '페르시아', '»', '문학이나', '»', '문화에', '»', '있어서', '»', '가장', '»', '불모', '(', '不', '毛', ')', '의', '»', '시기였다', '.']\n",
      "s : ['무굴', '»', '제국의', '»', '통일이', '»', '무너지고', '»', '있을', '»', '무렵', '»', '프랑스', ',', '»', '영국의', '»', '동인도회사', '»', '세력다툼이', '»', '전개되고', '»', '있었다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b01f03bea9442a9ac6b2be378ea8d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61c0b9ee94548cf9361b210d2d0eb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['전체', '»', '크기는', '»', '94', '»', 'x', '»', '274.8cm', '로', '»', '총', '»', '여섯', '»', '판으로', '»', '나뉘어', '»', '있으며', ',', '»', '금박지', '»', '위에', '»', '그려진', '»', '회화', '»', '작품이다', '.', '»', '교토의', '»', '어느', '»', '유흥집에서', '»', '음악과', '»', '놀이를', '»', '즐기는', '»', '사람들을', '»', '묘사해', '»', '놓았다', '.']\n",
      "s : ['병풍의', '»', '필법으로', '»', '미뤄보아', '»', '작가의', '»', '화풍은', '»', \"'\", '교카노', '»', '파', \"'\", '»', '(', '京', '狩', '野', ')', '를', '»', '따랐던', '»', '것으로', '»', '보인다', '.']\n",
      "s : ['더욱이', '»', '그', '»', '작가가', '»', '가노파나', '»', '그', '»', '부류', '»', '화파에', '»', '속했을', '»', '경우', ',', '»', '흔한', '»', '소재일수록', '»', '작가의', '»', '품위를', '»', '떨어뜨리는', '»', '일이라고', '»', '생각하였기에', '»', '작품을', '»', '완성하더라도', '»', '서명을', '»', '남기지', '»', '않는', '»', '경우가', '»', '많았다', '.']\n",
      "s : ['하지만', '»', '1898', '년', '»', '이사와가', '»', \"'\", '가쓰모치', \"'\", '라는', '»', '호를', '»', '썼으며', ',', '»', \"'\", '우키요', \"'\", '라는', '»', '이름', '»', '역시', '»', '1661', '년', '»', '아사이', '»', '료이가', '»', '화류계를', '»', '뜻하는', '»', '단어로', '»', '처음', '»', '쓰기', '»', '전이었기', '»', '때문에', '»', '다른', '»', '뜻을', '»', '품고', '»', '있다는', '»', '사실도', '»', '밝혀지면서', '»', '이러한', '»', '추측은', '»', '뒤집혀졌다', '.']\n",
      "s : ['작품', '»', '속의', '»', '글에는', '»', '히코네', '»', '병풍이', '»', '엔쿄', '»', '2', '년', '»', '(', '1745', '년', ')', '»', '에도의', '»', '시타야', '»', '(', '下', '谷', ')', '에', '»', '모셔져', '»', '있다고', '»', '쓰여져', '»', '있다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43b54e1401f4fae934eb0b0797832ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016fd91db6444c57ac8eeb5a7e5f8225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['형제회는', '»', '1979', '년', '»', '루이', '»', '마리', '»', '드', '»', '브리니르', '»', '수도사제에', '»', '의해', '»', '창설되었다', '.']\n",
      "s : ['헌법재판소', '»', '사무차장', '(', '憲', '法', '裁', '判', '所', '»', '事', '務', '次', '長', ')', '은', '»', '사무처장을', '»', '보좌하는', '»', '직위다', '.']\n",
      "s : ['2018', '년', '»', '12', '월', '»', '10', '일부터', '»', '7', '일간', '»', '실시되는', '»', '대한민국', '»', 'U-23', '»', '축구', '»', '국가대표팀', '»', '동계훈련', '»', '소집', '»', '명단에', '»', '포함되었다', '.']\n",
      "s : ['1964', '년에서', '»', '1965', '년까지', '»', '여러', '»', '나라에', '»', '제휴', '»', '단체가', '»', '발족되면서', '»', '국제', '»', '우나', '»', '보체', '»', '연맹이', '»', '결성되었다', '.', '»', '현재', '»', '20', '여개의', '»', '제휴', '»', '단체가', '»', '있다', '.']\n",
      "s : ['지역', '»', '교구장의', '»', '특별한', '»', '허락이나', '»', '승인', '»', '없이도', '»', '트리엔트', '»', '미사를', '»', '자유롭게', '»', '드리는', '»', '것을', '»', '허용한다는', '»', '내용의', '»', '자의교서', '»', '교황들이', '»', '시행됨에', '»', '따라', '»', '국제', '»', '우나', '»', '보체', '»', '연맹도', '»', '크게', '»', '확산되었다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b9766c7c964baf8f3b41b3fed373d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98acc1de3b444fba8e908643f5fbb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['\"', 'potpourri', '\"', '라는', '»', '단어는', '»', '프랑스어의', '»', '단어', '»', 'pot-pourri', '에서', '»', '유래하여', '»', '영어권으로', '»', '포함되었다', '.', '»', '프랑스의', '»', '단어는', '»', '두', '»', '개의', '»', '의미를', '»', '함축한다', '.', '»', '포푸리는', '»', '프랑스어로', '»', '다양한', '»', '재료를', '»', '포함하는', '»', '부르고스의', '»', '특산물인', ',', '»', '스페인식', '»', '스튜', '»', '올라', '»', '포드리다를', '»', '의미한다', '.', '»', '이', '»', '단어는', '»', '나폴레옹이', '»', '부르고스를', '»', '점령한', '»', '기간', '»', '동안', '»', '(', '1808-1813', ')', '»', '프랑스의', '»', '군인들이', '»', '베껴서', '»', '가져갔다', '.']\n",
      "s : ['좀', '»', '더', '»', '현대적인', '»', '포푸리는', '»', '꼭', '»', '향기가', '»', '나지', '»', '않더라도', '»', '장식적으로', '»', '생긴', '»', '건조한', '»', '식물과', ',', '»', '강력한', '»', '자연', ',', '»', '합성', '»', '향수', ',', '»', '그리고', '»', '흔히', '»', '염료로', '»', '구성되는데', ',', '»', '향기는', '»', '흔히', '»', '사용된', '»', '식물과는', '»', '관련이', '»', '없다', '.']\n",
      "s : ['포푸리를', '»', '만드는', '»', '데', '»', '사용되는', '»', '많은', '»', '식물이', '»', '있다', '.', '»', '연구자들은', '»', '95', '개의', '»', '과에서', '»', '균류와', '»', '지의류를', '»', '포함한', '»', '300', '개의', '»', '종들을', '»', '식별하였다', '.', '»', '마전자나무', '»', '등의', '»', '과실에서', '»', '몇몇', '»', '독성', '»', '재질이', '»', '확인되었다', '.', '»', '전통적인', '»', '포푸리에', '»', '사용되는', '»', '자연적으로', '»', '향기를', '»', '풍기는', '»', '식물들은', '»', '다음을', '»', '포함한다', ':']\n",
      "s : ['5', '남매', '»', '중', '»', '막내로', '»', '태어났으며', '»', '아버지가', '»', '처형된', '»', '당시', '»', '나이는', '»', '7', '살이었다', '.', '»', '아버지가', '»', '전범으로', '»', '잡혀갔을', '»', '때부터', '»', '니클라스는', '»', '아버지에', '»', '본성에', '»', '대해', '»', '알게', '»', '되었고', ',', '»', '훗날', '»', '책에', '»', '\"', '»', '아버지가', '»', '처형된', '»', '날', '»', '너무', '»', '기뻐서', '»', '그', '»', '장면을', '»', '상상하며', '»', '자위를', '»', '했다', '.', '»', '\"', '는', '»', '충격적인', '»', '글을', '»', '쓰기도', '»', '했다', '.']\n",
      "s : ['《', '스승의', '»', '은혜', '》', '는', '»', '강소천이', '»', '작사하고', '»', '권길상이', '»', '작곡한', '»', '노래로', ',', '»', '대한민국에서', '»', '스승의', '»', '날에', '»', '주로', '»', '불린다', '.', '»', '특히', '»', '학창', '»', '시절', '»', '스승에', '»', '대한', '»', '감사의', '»', '마음을', '»', '담아', '»', '애창된다', '.', '»', '가사는', '»', '\"', '스승의', '»', '은혜는', '»', '하늘같아서', '...', '»', '참되거라', '»', '바르거라', '\"', '와', '»', '같으며', '»', '전인격적인', '»', '가르침을', '»', '준다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b363ef76af3c43338cc4bfc54933168a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########  key error : (17, 20) ###########\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24032782e0a042f986d7b9cc5f08da38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['후임인', '»', '푸미사나니코네', '»', '수상은', '»', '전임수상의', '»', '연정을', '»', '파기하고', ',', '»', '라오스에', '»', '대한', '»', '공산주의', '»', '침투를', '»', '방지한다는', '»', '구실로', '»', '공산주의와의', '»', '결별을', '»', '선언하고', '»', '영세중립', '»', '정책을', '»', '지양하고', '»', '반공외교정책으로', '»', '전환함으로써', '»', '라오스의', '»', '연립정부는', '»', '붕괴되었고', '»', '영세중립', '»', '정책도', '»', '수포로', '»', '돌아가게', '»', '되었다', '.']\n",
      "s : ['더', '»', '나아가', '»', '지미', '»', '카터', '(', 'James', '»', 'E.', '»', 'Carter', ')', '»', '대통령이', '»', '1976', '년', ',', '»', '에드윈', '»', '라이샤워', '(', 'Edwin', '»', 'Reischauer', ')', '»', '교수가', '1976', '년', ',', '»', '오란', '»', '영', '(', 'Oran', '»', 'R.', '»', 'Young', ')', '»', '교수가', '»', '1983', '년', ',', '»', '글렌', '»', '페이지', '(', 'Glenn', '»', 'Paige', ')', '»', '교수가', '»', '1991', '년', '»', '8', '월', '»', '한국의', '»', '영세중립을', '»', '주장했다', '.']\n",
      "s : ['로스로리엔', '(', 'Lothl', 'ó', 'rien', ')', '은', '»', '《', '실마릴리온', '》', ',', '»', '《', '반지의', '»', '제왕', '》', ',', '»', '《', '호빗', '》', '에', '»', '등장하는', '»', '장소다', '.', '»', '1', '시대', '»', '이후', '»', '벨레리안드가', '»', '침수되자', '»', '본격적으로', '»', '2', '시대부터', '»', '언급된다', '.']\n",
      "s : ['서로', '»', '부자관계였던', '»', '이들에', '»', '대해', '»', '알려진', '»', '바는', '»', '거의', '»', '없으나', ',', '»', '그들의', '»', '죽음', '»', '이후', '»', '안개산맥을', '»', '넘어온', '»', '켈레보른과', '»', '갈라드리엘이', '»', '4', '시대', '»', '초엽까지', '»', '공동으로', '»', '다스렸다', '.']\n",
      "s : ['지상파', '»', '방송사', '»', 'KBS', '가', '»', '컨버전스티비와', '»', '공동기획', '»', '제작하여', '»', '동영상플랫폼인', '»', '푹', '(', 'POOQ', ')', '을', '»', '통해', '»', '공개된', '»', 'POOQ', '오리지널이다', '.', '»', '《', '넘버', '»', '식스', '》', '는', '»', '영담고', '»', '방송반에서', '»', '친해진', '»', '여섯', '»', '친구들의', '»', '엇갈린', '»', '사랑과', '»', '욕망을', '»', '그린', '»', '파격', '»', '멜로드라마로', '»', '이민혁', ',', '»', '백서이', ',', '»', '권영민', ',', '»', '우희', ',', '»', '강율', ',', '»', '한소은이', '»', '주인공을', '»', '맡았다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abc34a807824811a1fc9a1c37be1cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########  key error : (8, 18) ###########\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997aa5c1244141738d5334b4b2bec378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['케이트', '»', '르', '»', '봉', '(', 'Cate', '»', 'Le', '»', 'Bon', ',', '»', '1983', '년', '»', '3', '월', '»', '4', '일', '»', '~', '»', ')', '은', '»', '웨일스의', '»', '가수', ',', '»', '프로듀서이다', '.']\n",
      "s : ['더', '»', '도우', '(', 'The', '»', 'D', 'ø', ')', '는', '»', '프랑스', ',', '»', '핀란드의', '»', '인디', '»', '팝', '»', '듀오로', ',', '»', '2005', '년', '»', '프랑스', '»', '파리에서', '»', '결성되었다', '.', '»', '2008', '년', '»', '데뷔', '»', '앨범', '»', '\"', 'A', '»', 'Mouthful', '\"', '»', '을', '»', '발매했다', '.']\n",
      "s : ['4.', '»', '국방부', '»', '독서코칭', '»', '담당', '»', '교수']\n",
      "s : ['솔라항공', '(', ',', '»', ')', '은', '»', '돈므앙', '»', '국제공항에', '»', '본사를', '»', '둔', '»', '태국의', '»', '항공사였다', '.', '»', '이', '»', '항공사는', '»', '2010', '년에', '»', '모든', '»', '운항을', '»', '중단했다', '.']\n",
      "s : ['차오윈딩', '(', ',', '»', '1989', '년', '»', '11', '월', '»', '22', '일', '»', '~', '»', ')', '은', '»', '중국의', '»', '축구', '»', '선수이다', '.', '»', '포지션은', '»', '미드필더', ',', '»', '윙어이며', '»', '현재', '»', '중국', '»', '슈퍼리그의', '»', '상하이', '»', '뤼디', '»', '선화', '»', '소속이다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2810a8d7234f5b8f69c3b089f4277f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a692f2599ab4d72b9864ba74e3e2550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=850.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : ['33', '세', '»', '(', '만', '»', '32', '세', ')', '»', '쌍둥이자리', '»', '토끼띠', '»', '출생', '1987', '년', '»', '6', '월', '»', '18', '일', '»', '소속팀고양', '»', '오리온', '»', '오리온스', '»', '(', '센터', ')', '신체', '208cm', ',', '»', '105kg', '»', '사이트공식홈페이지경력사항경력사항', '2019.11', '»', '~', '»', '고양', '»', '오리온', '»', '오리온스', '2017', '»', '~', '»', '2019BC', '»', '지엘로나', '»', '고라', '2016', '»', '~', '»', '2017KK', '»', '부드스노스트', '2015', '»', '~', '»', '2016', '터키', '»', '텔레콤', '»', 'BK2014', '»', '~', '»', '2015', '라티오팜', '»', '울름', '2013', '»', '~', '»', '2014FC', '»', '바이에른', '»', '뮌헨', '2012', '»', '~', '»', '2013KK', '»', '츠르베나', '»', '즈베즈다', '2010', '»', '~', '»', '2012KK', '»', 'Hemofarm', '»', 'Stada', '»', 'Vrsac2009', '»', '~', '»', '2010KK', '»', '부드스노스트', '2007', '»', '~', '»', '2009KK', '»', 'Hemofarm', '»', 'Stada', '»', 'Vrsac2004', '»', '~', '»', '2007KK', '»', 'Hemofarm', '»', 'Vrsac', '경기성적경기성적', '»', '상세표날짜경기득점어시스트리바운드', '3', '점슛', '2019.12.20', '서울삼성', '1261902019', '~', '20', '시즌', '1313.773.1580.46']\n",
      "s : ['공격은', '»', 'OBEX', '»', 'Get', '»', 'Request', '로', '»', '.vcf', '»', '파일', '»', '(', '주소록', ')', '»', '또는', '»', '.vcs', '파일', '»', '(', '달력', ')', '과', '»', '같이', '»', '잘', '»', '알려진', '»', '파일', '»', '확장자로', '»', '보낸다', '.', '»', '만약', '»', '해당', '»', '기기의', '»', '펌웨어에', '»', '버그가', '»', '있다면', '»', '공격자는', '»', '사용자의', '»', '기기의', '»', '모든', '»', '파일에', '»', '접근할', '»', '수', '»', '있다', '.']\n",
      "s : ['다른', '»', '모든', '»', '무차별', '»', '대입', '»', '공격과', '»', '마찬가지로', ',', '»', '이', '»', '공격', '»', '방식의', '»', '주요한', '»', '어려움은', '»', '가능한', '»', 'MAC', '»', '주소들의', '»', '개수이다', '.', '»', '블루투스는', '»', '48', '비트', '»', '고유', '»', 'MAC', '»', '주소를', '»', '사용하며', ',', '»', '이', '»', '중', '»', '처음', '»', '24', '비트는', '»', '제조업체가', '»', '공통으로', '»', '사용한다', '.']\n",
      "s : ['모바일', '»', '기기의', '»', '경우', ',', '»', '이러한', '»', '유형의', '»', '공격은', '»', '국제모바일기기식별코드', '(', 'IMEI', ')', '를', '»', '목표로', '»', '하는', '»', '데', '»', '자주', '»', '이용된다', '.']\n",
      "s : ['마야콥스카야', '»', '역', '(', ')', '은', '»', '다음과', '»', '같은', '»', '역을', '»', '가리킨다', '.']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce8ed15d64c48e9993abc410470e21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=850.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\nfor i in tqdm(range(1,5)):\\n    df = pd.read_excel('./../Data/3_문어체_뉴스('+str(i)+')_191213.xlsx')\\n    parallel = df['ID 원문 번역문'.split(' ')]\\n    test_all_data = parallel[parallel['ID']%8 == 0]\\n    test_data = parallel[parallel['ID']%80 == 0]\\n    dev_data = parallel[parallel['ID']%8 == 4]\\n    train_data = parallel[parallel['ID']%4 != 0]\\n\\n    data_nm = 'test test_all dev train'.split(' ')\\n    #path = './en_es_data_3/'\\n    save_op = 'w' if i==1 else 'a'\\n    for j,ds in enumerate(tqdm([test_data, test_all_data, dev_data, train_data])): \\n        X = ds['원문']\\n        #X = to_bpe_sents8_test(X, vocabs,key_vars, sum_voc_vals)\\n        #  (1.3,3.2,14,1 (1.5,2.9,14,-1)  (1.3,2.8,14,0)\\n        X = to_bpe_sents10(X, vocabs,vocs_dict, logprob, key_vars, sum_voc_vals,extracted_vocs,(1.3,3.2,20,1),(6,5)) #default (1,3,12)\\n        print(X[:5])\\n        #X = to_normal_sents4(X, vocabs, josas, keywords, verbs, comb_check, key_vocs,key_vars, etc)\\n        _ = save_sents(X, path+data_nm[j]+'.ko',save_op)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_sents(sentences,fn,save_op):\n",
    "    p=re.compile(r'\\.$')\n",
    "    q = re.compile(r'\\s+')\n",
    "    z = re.compile(r'_ ') #영어로 번역할 때는 '_' 무시\n",
    "    u = re.compile(r'(?P<to_fix>[0-9]+)')\n",
    "                 \n",
    "    sents = []\n",
    "    for s in sentences:\n",
    "        s = [''.join([c for c in w if ord(c) < 55204]) for w in s ]\n",
    "        sents.append(q.sub(' ',u.sub(' \\g<to_fix> ',z.sub(' ',p.sub(' .',' '.join(s))))))\n",
    "        \n",
    "        #sents.append(z.sub(' ',q.sub(' ',p.sub(' .',' '.join(s)))))\n",
    "        \n",
    "    to_save = '\\n'.join(sents)   \n",
    "\n",
    "    with open(fn,save_op) as f:\n",
    "        f.write(to_save)  \n",
    "    \n",
    "    return to_save\n",
    "\n",
    "#vocabs = json_read(path+'vocabs.json')\n",
    "logprob = log_prob_by_len3(vocabs)\n",
    "sum_voc_vals = sum(vocabs.values())\n",
    "\n",
    "import copy\n",
    "vocs_dict = [{},{}]\n",
    "vocs_dict[0] = copy.deepcopy(vocabs)\n",
    "vocs_dict[1] = copy.deepcopy(vocabs)\n",
    "for i in range(2):\n",
    "    for k,l in vocs_dict[i].items():\n",
    "        vocs_dict[i][k] = k\n",
    "\n",
    "with open('./../train_Data/Kor_in_Preproc/train_ko_02','r') as f:\n",
    "    X = f.read().split('\\n')\n",
    "    \n",
    "n_step = 10000\n",
    "n_iter = len(X) // n_step +1\n",
    "\n",
    "for i in tqdm(range(22,n_iter)):\n",
    "    #if i==2:\n",
    "    #    continue\n",
    "    Xsub = X[i*n_step:(i+1)*n_step]\n",
    "    Xsub = [''.join([c for c in s if ord(c) < 55204]) for s in Xsub]\n",
    "    #X = to_normal_sents4(X, vocabs, josas, keywords, verbs, comb_check, key_vocs,key_vars, etc)\n",
    "    w_opt = 'w' if i==0 else 'a'    \n",
    "    Xsub = to_bpe_sents10(Xsub, vocabs,vocs_dict, logprob, key_vars, sum_voc_vals,extracted_vocs,(1.3,3.2,20,1),(6,5)) #default (1,3,12)\n",
    "    _ = save_sents(Xsub, './../train_Data/Kor_in_Preproc/pre_processed_train.ko',w_opt)\n",
    "    \n",
    "\"\"\" \n",
    "for i in tqdm(range(1,5)):\n",
    "    df = pd.read_excel('./../Data/3_문어체_뉴스('+str(i)+')_191213.xlsx')\n",
    "    parallel = df['ID 원문 번역문'.split(' ')]\n",
    "    test_all_data = parallel[parallel['ID']%8 == 0]\n",
    "    test_data = parallel[parallel['ID']%80 == 0]\n",
    "    dev_data = parallel[parallel['ID']%8 == 4]\n",
    "    train_data = parallel[parallel['ID']%4 != 0]\n",
    "\n",
    "    data_nm = 'test test_all dev train'.split(' ')\n",
    "    #path = './en_es_data_3/'\n",
    "    save_op = 'w' if i==1 else 'a'\n",
    "    for j,ds in enumerate(tqdm([test_data, test_all_data, dev_data, train_data])): \n",
    "        X = ds['원문']\n",
    "        #X = to_bpe_sents8_test(X, vocabs,key_vars, sum_voc_vals)\n",
    "        #  (1.3,3.2,14,1 (1.5,2.9,14,-1)  (1.3,2.8,14,0)\n",
    "        X = to_bpe_sents10(X, vocabs,vocs_dict, logprob, key_vars, sum_voc_vals,extracted_vocs,(1.3,3.2,20,1),(6,5)) #default (1,3,12)\n",
    "        print(X[:5])\n",
    "        #X = to_normal_sents4(X, vocabs, josas, keywords, verbs, comb_check, key_vocs,key_vars, etc)\n",
    "        _ = save_sents(X, path+data_nm[j]+'.ko',save_op)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 's', 'd', '5', '5']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaaaa = 'asd후리55'\n",
    "bbb = [c for c in aaaaa if ord(c) < 40000]\n",
    "bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55380, '\\ud855')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('\\ud854'), chr(55380+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['알려지', '  ', '다']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[special_to_normal3(normal_to_special(w,key_vars),key_vars,keep_double=False) for w in ['알리ㅓ지', 'ㅓㅆ', '다']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_to_special('놓았다',key_vars) in vocabs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ö' in vocabs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55380, 55203, 12593)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('\\ud854'),ord('힣'), ord('ㄱ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaa = [chr(i) for i in range(55203,55900)]\n",
    "print(aaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다. 그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다. 1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다. 그의 별명이 \"땅콩 농부\" (Peanut Farmer)로 알려졌다.',\n",
       " '카터는 이집트와 이스라엘을 조정하여, 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다.',\n",
       " '지미 카터는 대한민국과의 관계에서도 중요한 영향을 미쳤던 대통령 중 하나다. 인권 문제와 주한미군 철수 문제로 한때 한미 관계가 불편하기도 했다. 1978년 대한민국에 대한 북한의 위협에 대비해 한미연합사를 창설하면서, 1982년까지 3단계에 걸쳐 주한미군을 철수하기로 했다.',\n",
       " '12·12 군사 반란과 5.17 쿠데타에 대해 초기에는 강하게 비난했으나, 미국 정부가 신군부를 설득하는데, 한계가 있었고 결국 묵인하는 듯한 태도를 보이게 됐다.',\n",
       " '이 과정에서 미국 행정부와 갈등을 보이기도 했지만, 전직 대통령의 권한과 재야 유명 인사들의 활약으로 해결해 나갔다.',\n",
       " '2011년 4월 26일부터 29일까지 북한을 3일간 방문했다.',\n",
       " '하지만, 어느 과학의 분야들과는 달리, 자연계에서 관측되지 않는 개념들에 대해서까지 이론을 일반화 및 추상화시킬 수 있다는 차이가 있다고 한다.',\n",
       " '오늘날 수학은 자연과학, 공학, 의학뿐만 아니라, 경제학 등의 사회과학에서도 중요한 도구로서도 사용된다. 수학을 이런 분야들에 적용한 응용수학은 그 결과로써 수학 자체의 발전을 이끌고 새로운 분야들을 낳았다.',\n",
       " '교역•분배•과세 등의 인류의 사회 생활에 필요한 모든 계산을 수학이 담당해 왔고, 농경 생활에 필수적인 천문 관측과 달력의 제정, 토지의 측량 또한 수학이 직접적으로 관여한 분야이다. 고대 수학을 크게 발전시킨 나라로는 이집트, 인도, 그리스, 중국 등이 있다.',\n",
       " '수학의 각 분야들은 상업에 필요한 계산을 하기 위해, 숫자들의 관계를 이해하기 위해, 토지를 측량하기 위해, 그리고 천문학적 사건들을 예견하기 위해 발전되어왔다.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./../train_Data/train_ko_02','r') as f:\n",
    "    X = f.read().split('\\n')\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45696"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 57, 97, 122, 65, 90, 44032)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('0'),ord('9'),ord('a'),ord('z'),ord('A'),ord('Z'),ord('가')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', 0), ('1', 0), ('2', 0), ('3', 0), ('4', 0), ('5', 0), ('6', 0), ('7', 0), ('8', 0), ('9', 0)]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "print([(chr(i),1) if chr(i) in vocabs.keys() else (chr(i),0) for i in range(48,58)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_to_special('A',key_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(20, 4), (8, 0), (13, 4), (13, 20), (0, 20), (20, 0), (20, 1), (20, 5), (8, 1), (8, 20), (20, 8), (13, 5), (20, 13), (18, 20)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_to_single.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def dict_add(k,v,tgt):\n",
    "\n",
    "    if k in tgt.keys():\n",
    "        tgt[k] += v\n",
    "    else:\n",
    "        tgt[k] = v\n",
    "    return tgt\n",
    "\n",
    "def dict_subtract_part(to_del,vocX,rate):\n",
    "    for k,v in to_del.items():\n",
    "        if k in vocX.keys():\n",
    "            vocX[k] = vocX[k]-int(v*rate)\n",
    "    return vocX\n",
    "\n",
    "def vocab_split(vocX,to_split,rate):\n",
    "    \n",
    "    to_del ={}\n",
    "    X = {}\n",
    "    kwds = to_split\n",
    "    #to_skip = [normal_to_special(w,key_vars) for w in ['구한말']]\n",
    "    for k,v in kwds.items():\n",
    "        ks = normal_to_special(k,key_vars)\n",
    "        vs = normal_to_special(v,key_vars)\n",
    "        if ks in vocX.keys():\n",
    "            for x in vs.split(' '):\n",
    "                _ = dict_add(x,vocX[ks],X)  #k,v,tgt\n",
    "            _ = dict_add(ks,vocX[ks],to_del)\n",
    "    \n",
    "    _ = dict_subtract_part(to_del,vocX,rate)\n",
    "    \n",
    "    return vocX\n",
    "\n",
    "\n",
    "def vocab_adjust(vocX,to_adjust,rate,to_skip=[''], to_match = 0): #단어 첫 캐릭터 부터 검색하지 않는 경우의 수\n",
    "                                                                 #to_match=0 의 의미는 '모두 첫 캐릭터 부터 검색'\n",
    "    to_del ={}\n",
    "    aa = {}\n",
    "    bb = {}\n",
    "    cc = {}\n",
    "\n",
    "    kwds = to_adjust\n",
    "    pre_kwds = ['']*to_match+['^']*(len(kwds[to_match:]))\n",
    "    to_skip = [normal_to_special(w,key_vars) for w in to_skip]\n",
    "    for i,wk in enumerate(tqdm(kwds)):\n",
    "        wks = normal_to_special(wk,key_vars)\n",
    "        p = re.compile(pre_kwds[i]+wks)\n",
    "        nS = 0\n",
    "        for k,v in vocX.items():\n",
    "            \n",
    "            if p.search(k) is not None and k not in to_skip:\n",
    "                #print(special_to_normal3(k,key_vars,keep_double= False))\n",
    "                sl = k.find(wks)\n",
    "                el = sl +len(wks)                       \n",
    "                sects = [k[:sl], k[sl:el],k[el:]]\n",
    "                #print(special_to_normal3(k,key_vars,keep_double= False), sects)\n",
    "                for ik,dt in enumerate([aa,bb,cc]):\n",
    "                    _ = dict_add(sects[ik],v,dt)\n",
    "                dict_add(k,v,to_del)\n",
    "                nS += 1\n",
    "        \n",
    "        if nS==0:\n",
    "             _ = dict_add(wks,20,bb)\n",
    "                \n",
    "    vocX = dict_subtract_part(to_del,vocX,rate) \n",
    "    \n",
    "    return vocX, aa, bb, cc\n",
    "\n",
    "\n",
    "def magic4(s, z, k_args):\n",
    "    k=k_args[0]\n",
    "    fX = k_args[1]\n",
    "    tX = k_args[2]\n",
    "    k2 = k_args[3]\n",
    "    v=len(s)\n",
    "    X = min(2*k*(v-fX),0.4*(v-k2),2*k) if (v<7) else min(-0.2*k*(v-tX),2*k)\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def search_max_prob4(subword,sub_comb,vocabs,vocs_dict,logprob,sub_sum,z,k_args):\n",
    "\n",
    "    for j in reversed(range(1,len(subword))):\n",
    "        sb = [z.sub('',subword[:j]),z.sub('',subword[j:])]\n",
    "\n",
    "        if (sb[0] in vocs_dict[0].keys()) and (sb[1] in vocs_dict[1].keys()):\n",
    "\n",
    "            temp = [vocs_dict[0][sb[0]], vocs_dict[1][sb[1]]]\n",
    "            temp_sum = [np.log(vocabs[vocs_dict[i][s]])-logprob[len(s)] + magic4(s,z,k_args) for i,s in enumerate(sb)]        \n",
    "            #temp_sum = sum([np.log(vocabs[s])-logprob[len(s)]+min(8*np.log(len(s)/8),0) for s in temp])/2\n",
    "            if sum(temp_sum)/len(temp_sum) > sum(sub_sum)/len(sub_sum) : \n",
    "                sub_sum = temp_sum\n",
    "                sub_comb = temp\n",
    "                \n",
    "    return sub_comb,sub_sum\n",
    "\n",
    "\n",
    "\n",
    "def forward_check6(subword,vocabs,vocs_dict,z,logprob,k_args,recursive=False):\n",
    "    \n",
    "    zsub = z.sub('',subword)\n",
    "    if zsub in vocs_dict[1].keys():\n",
    "        ws_fw = [vocs_dict[1][zsub]]\n",
    "    else:\n",
    "        ws_fw = ['NotInVocabs']\n",
    "        zsub = 'NotInVocabs'\n",
    "    \n",
    "    pre_sub_sum = sub_sum = [np.log(vocabs[vocs_dict[1][zsub]])-logprob[len(zsub)]+magic4(zsub,z,k_args)]\n",
    "        \n",
    "    if len(subword) > 1:        \n",
    "        \n",
    "        sub_comb = ws_fw\n",
    "        \n",
    "        #dir_to_check = reversed(range(1,len(subword))) #if forward else range(1,len(subword))\n",
    "        \n",
    "        sub_comb, sub_sum = search_max_prob4(subword,sub_comb, vocabs,vocs_dict,logprob,pre_sub_sum,z,k_args) \n",
    "        if recursive == True and len(sub_comb)>1:\n",
    "            \n",
    "            sub_comb1, sub_sum1 = forward_check6(sub_comb[0],vocabs,vocs_dict,z,logprob,k_args,recursive=False)\n",
    "            sub_comb = sub_comb1 + sub_comb[1:]\n",
    "            sub_sum = sub_sum1 + sub_sum[1:]            \n",
    "            \n",
    "            sub_comb2, sub_sum2 = forward_check6(sub_comb[-1],vocabs,vocs_dict,z,logprob,k_args,recursive=False)\n",
    "            sub_comb = sub_comb[:-1] + sub_comb2\n",
    "            sub_sum = sub_sum[:-1] + sub_sum2\n",
    "        \n",
    "        if (pre_sub_sum < sum(sub_sum)/len(sub_sum)):\n",
    "            ws_fw = sub_comb \n",
    "        else:\n",
    "            sub_comb = pre_sub_sum\n",
    "            \n",
    "    return ws_fw, sub_sum\n",
    "\n",
    "\n",
    "def get_vocs_dict(vocabs):\n",
    "    \n",
    "    vocs_dict = [{},{}]\n",
    "    z = re.compile(r'걟+')\n",
    "    zz = re.compile(r'걟걟$')\n",
    "\n",
    "    for k,v in vocabs.items():\n",
    "        if zz.search(k) is not None:\n",
    "            vocs_dict[1][zz.sub('',k)] = k\n",
    "            continue    \n",
    "        zk = z.sub('',k)\n",
    "        if zk not in vocs_dict[0].keys():\n",
    "            vocs_dict[0][zk] = [k]\n",
    "        else:\n",
    "            vocs_dict[0][zk] +=[k]\n",
    "    for k,l in vocs_dict[0].items():\n",
    "        vocs_dict[0][k] = sorted(l,key=lambda x:len(x), reverse=True)[0]  \n",
    "        \n",
    "    temp_dict = vocs_dict[0].copy()\n",
    "    for k,v in vocs_dict[1].items():\n",
    "        temp_dict[k] = v\n",
    "    vocs_dict[1] = temp_dict\n",
    "    \n",
    "    return vocs_dict\n",
    "\n",
    "def to_bpe_sents10(sentences, vocabs,vocs_dict, logprob, key_vars, sum_voc_vals,extracted_vocs,k_args, cut):\n",
    "            \n",
    "    vocabs.pop('',1) \n",
    "\n",
    "    vocabs['NotInVocabs'] = 0.001\n",
    "    josas =  list(chain(*[[k for k in extracted_vocs[kc].keys() if len(k)>0] for kc in ['mids','subs']]))\n",
    "    verbs = [k for k in extracted_vocs['verbs'] if len(k)>0]    \n",
    "    mids = ['었', '았', 'ㅓㅆ', 'ㅏㅆ', 'ㅣㅆ', 'ㅆ', '어', '아', 'ㅓ', 'ㅏ', 'ㅣ', 'ㄴ','ㄹ','ㅁ','게']\n",
    "    mids = [normal_to_special(w,key_vars) for w in mids]\n",
    "    vms = list(set(verbs+josas+mids))\n",
    "    \n",
    "    \n",
    "    len_cut = cut[0]\n",
    "    log_cut = cut[1]\n",
    "    \n",
    "    all_s = []\n",
    "    #fre_sum = sum(vocabs.values())\n",
    "    fre_sum = sum_voc_vals\n",
    "    p = re.compile(r'[^가-힣ㄱ-ㅎㅏ-ㅣ_\\-]+')\n",
    "    p2 = re.compile(r'[가-힣]')\n",
    "    q = re.compile(r'\\.$')\n",
    "    r = re.compile(r'\\s+')\n",
    "    #u = re.compile(r'(?P<to_fix>[,\\(\\)\\'\\\"\\<\\>])')\n",
    "    u = re.compile(r'(?P<to_fix>[^A-Za-z가-힣ㄱ-ㅎㅏ-ㅣ0-9_\\-\\.])')\n",
    "    uek = re.compile(r'(?P<en>[A-Za-z])(?P<ko>[가-힣ㄱ-ㅎ])')\n",
    "    uke = re.compile(r'(?P<ko>[가-힣ㄱ-ㅎ])(?P<en>[A-Za-z])')\n",
    "    uknk = re.compile(r'(?P<notko>[^가-힣ㄱ-ㅎㅏ-ㅣ])(?P<ko>[가-힣ㄱ-ㅎ])')\n",
    "    ukkn = re.compile(r'(?P<ko>[가-힣ㄱ-ㅎ])(?P<notko>[^가-힣ㄱ-ㅎㅏ-ㅣ])')\n",
    "    z = re.compile(r'걟+')\n",
    "    z2 = re.compile(r'»')\n",
    "    zz = re.compile(r'걟걟$')\n",
    "    #u1 = re.compile(r'‘')\n",
    "    #u2 = re.compile(r'”')\n",
    "    #ord('“'),ord('‘'),ord('\"'),ord(\"'\")\n",
    "    #(8220, 8216, 34, 39)\n",
    "\n",
    "                   \n",
    "    for ii,s in enumerate(tqdm(sentences)):\n",
    "        st = []\n",
    "        for c in s:\n",
    "            if ord(c) == 8220 or ord(c) == 8221:\n",
    "                st.append(chr(34))\n",
    "            elif ord(c) == 8216 or ord(c) == 8217:\n",
    "                st.append(chr(39))\n",
    "            elif c == '»':\n",
    "                st.append('>>')\n",
    "            else:\n",
    "                st.append(c)\n",
    "\n",
    "        st = ''.join(st)\n",
    "        st = r.sub(' ',st).strip().split(' ')\n",
    "        st = '»'.join(st)\n",
    "        st = uek.sub('\\g<en> \\g<ko>', st)\n",
    "        st = uke.sub('\\g<ko> \\g<en>', st)\n",
    "        st = uknk.sub('\\g<notko> \\g<ko>', st)\n",
    "        st = ukkn.sub('\\g<ko> \\g<notko>', st)\n",
    "        st = u.sub(' \\g<to_fix> ',st)\n",
    "        #st = u1.sub(' ‘',st)\n",
    "        #st = u2.sub(' ”',st)\n",
    "        st = q.sub(' .',st)\n",
    "        st = r.sub(' ',st)\n",
    "        st = [wd for wd in st.strip().split(' ')]\n",
    "        \"\"\"\n",
    "        sent = []\n",
    "        for wd in st.strip().split(' '):\n",
    "            if wd[-1] == '_':\n",
    "                sent += [wd]\n",
    "            else:\n",
    "                sent += [wd,'_']\n",
    "        \"\"\"\n",
    "        #st = r.sub(' ',' '.join([u.sub(' \\g<to_fix> ',wd) for wd in st])).split(' ')\n",
    "            \n",
    "        if ii<5:\n",
    "            print(\"s : {}\".format(st))\n",
    "        sentence = []\n",
    "        for w in st:\n",
    "            if (w == '') or (w ==' '):continue\n",
    "\n",
    "            if p.search(w) is not None:                       \n",
    "                #sentence += [w,'_']\n",
    "                sentence += [z2.sub('__',w)]\n",
    "                continue                    \n",
    "            #print(w)\n",
    "            n_fw = []\n",
    "            n_bw = []\n",
    "\n",
    "            bpe_w= ''.join([chr(i+BASE_CODE) for i in counter_convert2(w,key_vars)[1]])\n",
    "            \n",
    "            s_w = bpe_w + '걟걟'\n",
    "            \"\"\" \n",
    "            if s_w in vocabs.keys():\n",
    "                n_bf = [s_w]\n",
    "            elif z.sub('',s_w[:-1]) in vocabs.keys():\n",
    "                n_bf = [z.sub('',s_w[:-1])]\n",
    "            else:\n",
    "                n_bf = []\n",
    "            \"\"\"            \n",
    "            #n_fw = forward_check3(s_w,vocabs,logprob,fre_sum)\n",
    "            \n",
    "            n_word = []  \n",
    "            \n",
    "            ifw = 0  \n",
    "            pre_len = 0\n",
    "            \n",
    "            while len(z.sub('',s_w)):           \n",
    "                #print(s_w)\n",
    "                pre_sw = s_w\n",
    "                #print(\"s_w : {}\".format(s_w))\n",
    "                \n",
    "\n",
    "                n_fw,_ = forward_check6(s_w,vocabs,vocs_dict,z,logprob,k_args,recursive=True)\n",
    "                if n_fw[0] != 'NotInVocabs':\n",
    "                    n_word += n_fw\n",
    "                    #sentence += n_word + ['걟'] if n_word[-1][-1] !='걟' else n_word\n",
    "                    break\n",
    "\n",
    "                #nj = len(s_w)-ifw+2\n",
    "                #for i in reversed(range(1,len(s_w)-ifw+1)):\n",
    "                #    if s_w[i:nj] in josas:\n",
    "                #        nj = i\n",
    "                \n",
    " \n",
    "                for i in reversed(range(1,len(s_w)-ifw)): # len(s_w) -2 로 한 것은 n_bf와 중복을 피하기 위해 ...\n",
    "                    #if (s_w[i:] == '걟갧') or (s_w[i:] == '걟'):continue\n",
    "                    \n",
    " \n",
    "                    if s_w[:i] in vocabs.keys():\n",
    "                        res_w = special_to_normal(s_w[i:],key_vars)\n",
    "                        if ord(res_w[0]) not in range(12593, 12644):\n",
    "       \n",
    "                            n_fw,_= forward_check6(s_w[:i],vocabs,vocs_dict,z,logprob,k_args,recursive=True)\n",
    "                            n_word += n_fw\n",
    "\n",
    "                            s_w = s_w[i:]\n",
    "                            break \n",
    "                    \n",
    "                        elif ((s_w[:i] in vms and res_w[0] in ['ㄴ','ㄹ','ㅁ','ㅆ','ㅏ','ㅓ'])\n",
    "                              or (s_w[:i] in extracted_vocs['nouns'] and res_w[0] in ['ㅅ'])):\n",
    "                            n_fw,_= forward_check6(s_w[:i],vocabs,vocs_dict,z,logprob,k_args,recursive=True)\n",
    "                            n_word += n_fw\n",
    "\n",
    "                            s_w = s_w[i:]\n",
    "                            break                             \n",
    "                    \n",
    "                                       \n",
    "                if s_w == pre_sw:\n",
    "                    not_in_vocabs = 1\n",
    "                    for i in range(len(s_w)):\n",
    "                        if z.sub('',s_w[i:]) in vocs_dict[0].keys():\n",
    "                            n_word += [\"<\" + s_w[:i] +\">\"] + forward_check6(s_w[i:],vocabs,vocs_dict,z,logprob,k_args,recursive=True)[0]\n",
    "                            insert_voc(vocabs,\"<\" + s_w[:i] +\">\",1)\n",
    "                            not_in_vocabs = 0                            \n",
    "                            break\n",
    "                    if not_in_vocabs == 1:\n",
    "                        n_word.append(\"<\" + s_w +\">\")\n",
    "                        insert_voc(vocabs,\"<\" + s_w +\">\",1)\n",
    "                    break\n",
    " \n",
    "\n",
    "            n_w = [z.sub('걟',w) for w in n_word[:-1]] + [n_word[-1]] if len(n_word)>1 else n_word\n",
    "    \n",
    "            #if ii in range(3):\n",
    "            #    print(ii, [special_to_normal(ss,key_vars) for ss in n_w])\n",
    "                        \n",
    "            if len(n_w)>1:\n",
    "                window = 2\n",
    "                to_continue = 1\n",
    "                \n",
    "                while to_continue:\n",
    "                    \n",
    "                    to_continue = 0\n",
    "                \n",
    "                    mx = 1.4 if n_w[-1] not in josas else 1.0\n",
    "                    \n",
    "                    for i in range(window,len(n_w)+1):\n",
    "                        \n",
    "                        to_ch = ''.join(n_w[i-window:i])\n",
    "                        if to_ch not in vocabs:\n",
    "                            continue\n",
    "                        \n",
    "                        nx = min(max(mx, 1.+(len(n_w)-i)*0.2), 1.4) # 조사의 잔존가능성은 유지하고 조사가 아닌 경우 가능한 결합\n",
    "                            \n",
    "                        temp_sum = [np.log(vocabs[ww])-logprob[len(ww)] + magic4(ww,z,k_args) for ww in n_w[i-window:i]]\n",
    "                        if sum(temp_sum)/len(temp_sum) < np.log(vocabs[to_ch])*nx-logprob[len(to_ch)] + magic4(to_ch,z,k_args):\n",
    "                            n_w = n_w[:i-window]+[to_ch]+n_w[i:]\n",
    "                            to_continue = 1 \n",
    "                            window = 2  # 결합된 것이 있으면 원도우는 다시 2로 세팅\n",
    "                            break\n",
    "                    \n",
    "                    if to_continue == 0:\n",
    "                        if window < len(n_w):\n",
    "                            window += 1\n",
    "                            to_continue = 1           \n",
    "            \n",
    "            \"\"\"\n",
    "            n_bw = []\n",
    "            nj = 0\n",
    "            \n",
    "            #print([special_to_normal(ss,key_vars) for ss in n_w])\n",
    "\n",
    "            for i, ww in enumerate(reversed(n_w)):\n",
    "                \n",
    "                if ww in mids:\n",
    "                    temp = ww\n",
    "                    nj = 1\n",
    "                    \n",
    "                elif nj==1:\n",
    "                    if ww in verbs:\n",
    "                        n_bw +=[temp,ww]\n",
    "                        nj = 0\n",
    "                    else:\n",
    "                        break\n",
    "                    \n",
    "                elif ww in josas:\n",
    "                    n_bw.append(ww)\n",
    "                    \n",
    "                elif i==0 and len(special_to_normal3(ww,key_vars,keep_double=False))<2:\n",
    "                    break\n",
    "                    \n",
    "                elif ww in verbs:\n",
    "                    wws = special_to_normal3(ww,key_vars,keep_double=False)\n",
    "                    if len(wws)>1:\n",
    "                        n_bw.append(ww)\n",
    "                    elif wws in ['당','하','해','되','이','오','가','지']:\n",
    "                        n_bw.append(ww)\n",
    "                    else:\n",
    "                        break\n",
    "                        \n",
    "                    \n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            n_rw = n_w[:-len(n_bw)] if len(n_bw)>0 else n_w  \n",
    "            \n",
    "            #if normal_to_special('검',key_vars) in n_w: \n",
    "            #    print('\\n\\n',n_rw, [special_to_normal(wkk,key_vars) for wkk in n_w],'\\n\\n\\n')\n",
    "\n",
    " \n",
    "            if len(n_rw) > 1:\n",
    "                \n",
    "                len_avg = sum([len(ww) for ww in n_rw])/len(n_rw)\n",
    "                log_avg = sum([np.log(vocabs[ww])*len(ww)/len_avg for ww in n_rw])/len(n_rw) * (len_avg/6.0)              \n",
    "                \n",
    "                if log_avg < log_cut and len_avg < len_cut: \n",
    "                    \n",
    "                    #if ''.join(n_rw) in vocabs().keys(): # 추가된 부분\n",
    "             \n",
    "                    n_rw = [''.join(n_rw)]\n",
    "                \n",
    "                else:\n",
    "                    n_temp = ['']\n",
    "                    l = len(n_rw)\n",
    "                    pre_pop = 0\n",
    "                    for i,rw in enumerate(n_rw):\n",
    "                        wn = special_to_normal3(rw,key_vars,keep_double=False)    \n",
    "                        if pre_pop == 1:\n",
    "                            n_temp[-1] = n_temp[-1]+rw\n",
    "                            pre_pop = 0\n",
    "                        \n",
    "                        elif len(rw) < 2:\n",
    "                            n_temp[-1] = n_temp[-1]+rw\n",
    "                            pre_pop = 1                            \n",
    "                            \n",
    "                        elif len(wn) > 1:\n",
    "                            if ord(wn[0]) in range(12593,12644) and ord(wn[-1]) in range(12593,12644):\n",
    "                                n_temp[-1] = n_temp[-1]+rw\n",
    "                                pre_pop = 1\n",
    "                            elif ord(wn[0]) in range(12593,12644):\n",
    "                                n_temp[-1] = n_temp[-1]+rw\n",
    "                            elif ord(wn[-1]) in range(12593,12644):\n",
    "                                n_temp.append(rw)\n",
    "                                pre_pop = 1\n",
    "                            else:\n",
    "                                n_temp.append(rw)\n",
    "\n",
    "                        else:\n",
    "                              \n",
    "                            w1 = ''.join(n_rw[-l+i-1:i])\n",
    "                            w2 = ''.join(n_rw[i:i+1])\n",
    "                            if w1 != rw and w1 in vocabs.keys():\n",
    "                                if w2 in vocabs.keys():\n",
    "                                    if vocabs[w1] > vocabs[w2]: \n",
    "                                        n_temp[-1] = n_temp[-1]+rw\n",
    "                                    else:\n",
    "                                        n_temp.append(rw)\n",
    "                                        pre_pop = 1\n",
    "                                else:\n",
    "                                    n_temp[-1] = n_temp[-1]+rw\n",
    "                            else:\n",
    "                                if w2 in vocabs.keys():\n",
    "                                    n_temp.append(rw)\n",
    "                                    pre_pop = 1 \n",
    "                                else:\n",
    "                                    n_temp[-1] = n_temp[-1]+rw #양방향 모두 의미 없으면 3개 글자 모두 합쳐 하나로!\n",
    "                                    pre_pop = 1 \n",
    "\n",
    "                    n_rw = [ww for ww in n_temp if ww!='']\n",
    "\n",
    "            n_w = n_rw + n_bw[::-1]                \n",
    "            \"\"\"            \n",
    "            #if ii in range(3):\n",
    "            #    print(ii,'last',[special_to_normal(w,key_vars) for w in n_w])\n",
    "            #n_w = [z2.sub('_',chars) for chars in n_word]\n",
    "            #sentence += n_w + ['걟'] if n_w[-1][-1] !='걟' else n_w\n",
    "            \n",
    "            sentence +=n_w\n",
    "        #sentence = [sentence[0]] + [wds  for i,wds in enumerate(sentence[1:]) if sentence[i][-1] !='걟걟']\n",
    "        all_s.append(sentence)\n",
    "\n",
    "    sents = []\n",
    "    for s in tqdm(all_s):\n",
    "        sent = []\n",
    "        for w in s:\n",
    "            #to_add = special_to_normal(w,key_vars) if p2.search(w) is not None else w\n",
    "            to_add = w if p2.search(w) is None else special_to_normal3(w,key_vars,keep_double=False)\n",
    "            \"\"\"\n",
    "            ######\n",
    "            special_to_normal 을 고칠지 한글로 말들어진 후에 고칠 지 검토!!!\n",
    "            count_utils 의 double_vowel_lookup2(JUNGSUNG_LIST) 와  \n",
    "            counter_utils 의 counter_ind_char2(idx, key_vars,keep_double=True) 수정중\n",
    "            ##########\n",
    "            \"\"\"\n",
    "            sent.append(to_add)    \n",
    "        #sents.append([special_to_normal(w,key_vars) for w in s])\n",
    "        sents.append(sent)\n",
    "    \n",
    "    return sents \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'갠걌'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_to_special('ㅓㅆ',key_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_to_normal3('갠걌',key_vars,keep_double=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 76, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('갠')-BASE_CODE,ord('걌')-BASE_CODE,ch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
