{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_preproc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preproc.py\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "import json\n",
    "import re\n",
    "from app_utils import to_start, rid_blank, preproc_num, to_normal\n",
    "from trns.preproc_En import pre_en, preproc_en\n",
    "from trns.preproc_kor import preproc_ko2en\n",
    "\n",
    "\n",
    "def preProc(X, lang, to_start, pre_ko, preproc_en, en_vocs):\n",
    "    \n",
    "    #X = to_start(X)\n",
    "    \n",
    "    if lang == 'en':\n",
    "        #X = pre_en(X)\n",
    "        X = preproc_en(X,en_vocs)\n",
    "        X = preproc_num(X)\n",
    "       \n",
    "    else:\n",
    "        X = pre_ko.forward(X)\n",
    "        X = preproc_num(X) \n",
    "\n",
    "    return X \n",
    "\n",
    "\n",
    "def preProc_save(X, step_num, lang,to_start, pre_ko, preproc_en, en_vocs,f_toSave):\n",
    "    \n",
    "    #n_iter = len(X) // step_num +1\n",
    "    n_iter = len(X) // step_num + min((len(X) % step_num), 1) * 1\n",
    "\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        Xsub = X[i*step_num:(i+1)*step_num]\n",
    "        #Y = list(chain(*[preProc(s, 'en', to_start, pre_ko, preproc_en, en_vocs) for s in Xsub]))\n",
    "        Y = preProc(Xsub, lang, to_start, pre_ko, preproc_en, en_vocs)\n",
    "        with open(f_toSave, 'w' if i==0 else 'a') as f:\n",
    "            f.write('\\n'.join(Y)+'\\n')\n",
    "    return Y\n",
    "\n",
    "#with open('to_preproc/pre_processed_short05.en', 'r') as f:\n",
    "#    X = f.read().split('\\n')[:100]\n",
    "\n",
    "\n",
    "def sanitize_input(in_file):\n",
    "    \n",
    "    p = re.compile('[\\`\\^]')\n",
    "    p1 = re.compile('\\`')\n",
    "    p2 = re.compile('\\^')\n",
    "    \n",
    "    with open(in_file, 'r') as f:\n",
    "        X = f.read().split('\\n')\n",
    "        X = [s+'.' for s in X]\n",
    "\n",
    "    if len([s for s in X if p.search(s) is not None])>0:\n",
    "        print(\"`^ id detected !!!!\")\n",
    "        print([(i,s) for i,s in enumerate(X) if p.search(s) is not None])\n",
    "\n",
    "    X = [p2.sub('ˆ',p1.sub(\"'\",s)) for s in X] #if p.search(s) is None]\n",
    "    \n",
    "    return X\n",
    "\n",
    "pre_ko = preproc_ko2en()\n",
    "en_vocs = pre_en()\n",
    "\n",
    "path0 = 'innovators/'\n",
    "f_toSave = path0+'new_output/dev8.'\n",
    "step_num = 10000\n",
    "\n",
    "X = sanitize_input(path0+'Xen')\n",
    "Y = preProc_save(X, step_num, 'en', to_start, pre_ko, preproc_en, en_vocs,f_toSave+'en')\n",
    "\n",
    "X = sanitize_input(path0+'Xko')\n",
    "Y = preProc_save(X, step_num, 'ko', to_start, pre_ko, preproc_en, en_vocs,f_toSave+'ko')\n",
    "\n",
    "\"\"\"\n",
    "with open('innovators/Xen', 'r') as f:\n",
    "    X = f.read().split('\\n')\n",
    "    X = [s+'.' for s in X]\n",
    "    \n",
    "if len([s for s in X if p.search(s) is not None])>0:\n",
    "    print(\"`^ id detected !!!!\")\n",
    "    print([(i,s) for i,s in enumerate(X) if p.search(s) is not None])\n",
    "    \n",
    "X = [p2.sub('ˆ',p1.sub(\"'\",s)) for s in X] #if p.search(s) is None]\n",
    "\"\"\"  \n",
    "\n",
    "\"\"\"\n",
    "step_num = 10000\n",
    "n_iter = len(X) // step_num + min((len(X) % step_num), 1) * 1\n",
    "for i in tqdm(range(n_iter)):\n",
    "    Xsub = X[i*step_num:(i+1)*step_num]\n",
    "    #Y = list(chain(*[preProc(s, 'en', to_start, pre_ko, preproc_en, en_vocs) for s in Xsub]))\n",
    "    Y = preProc(Xsub, 'en', to_start, pre_ko, preproc_en, en_vocs)\n",
    "    with open('innovators/dev8.en', 'w' if i==0 else 'a') as f:\n",
    "        f.write('\\n'.join(Y)+'\\n')\n",
    "\n",
    "\n",
    "with open('innovators/Xko', 'r') as f:\n",
    "    X = f.read().split('\\n')\n",
    "    \n",
    "if len([s for s in X if p.search(s) is not None])>0:\n",
    "    print(\"`^ id detected !!!!\")\n",
    "    print([(i,s) for i,s in enumerate(X) if p.search(s) is not None])\n",
    "    \n",
    "X = [p2.sub('ˆ',p1.sub(\"'\",s)) for s in X] #if p.search(s) is None]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "step_num = 10000\n",
    "n_iter = len(X) // step_num + min((len(X) % step_num), 1) * 1\n",
    "for i in tqdm(range(n_iter)):\n",
    "    Xsub = X[i*step_num:(i+1)*step_num]\n",
    "    #Y = list(chain(*[preProc(s, 'en', to_start, pre_ko, preproc_en, en_vocs) for s in Xsub]))\n",
    "    Y = preProc(Xsub, 'ko', to_start, pre_ko, preproc_en, en_vocs)\n",
    "    with open('innovators/dev8.ko', 'w' if i==0 else 'a') as f:\n",
    "        f.write('\\n'.join(Y)+'\\n')\n",
    "\"\"\"\n",
    "\n",
    "len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ted_data/to_train/ted_train.en', 'r') as f:\n",
    "    X = f.read().split('\\n')\n",
    "\n",
    "with open('ted_data/to_train/ted_train.ko', 'r') as f:\n",
    "    Y = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166213, 166213)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"^ and _ the _ pin head ^ i've _ made _ green _ around _ there _ by _ scrap ing _ the _ particle s _ off _ a _ green _ shirt _ and _ then _ pressed _ onto _ the _ needle _ .\",\n",
       "  \"^ it's _ very _ painstaking _ work _ , _ but _ the _ best _ thing s _ come _ in _ small _ package s _ .\",\n",
       "  '_ ( ^ laughter _ ) ^ bruno ^ gi us sani _ : ^ willard ^ wigan _ !'],\n",
       " ['_ 그리 고 _ 이 _ 못 _ 머리 의 _ 초록색 은 _ 초록색 _ 셔츠 의 _ 입자 를 _ 긁 어내 어 _ 못 _ 머리 에 _ 눌러 주 었습니다 _ .',\n",
       "  '_ 제 _ 작품 _ 활동 은 _ 꽤 나 _ 공 이 _ 들어가 는 _ 일 이 ㅂ니다 . _ 하 지만 _ 최고 의 _ 것 들 은 _ 항 상 _ 작 은 _ 것 에서 부터 _ 비롯 되는 _ 거 니까 요 _ .',\n",
       "  '_ ( _ 웃음 _ ) _ 부르 노 _ 지우 사 니 _ : _ 윌 라 드 _ 위 간 _ 씨 이 ㅓㅆ 습니다 _ ! _'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-3:], Y[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('ˆ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import re\n",
    "p = re.compile(\"\\([^\\)]*[^0-9\\~\\-\\–\\s\\.\\,\\;\\:\\%가-힣a-zA-Z]+[^\\(]*\\)\")\n",
    "q = re.compile('^\\(')\n",
    "z = re.compile('\\s+')\n",
    "z1 = re.compile(r'\\\\')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ted_data/to_train/ted_train.en', 'r') as f:\n",
    "    X = f.read().split('\\n')\n",
    "\n",
    "with open('ted_data/to_train/ted_train.ko', 'r') as f:\n",
    "    Y = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ _ 이쪽 은 ^ bill ^ lange _ 이 고 _ , _ 저 는 ^ david ^ gallo 이 ㅂ니다',\n",
       " '_ 우리 는 _ 여러분 에게 _ 바닷속 _ 이야기 를 _ 영상 과 _ 함께 _ 들리 ㅓ 주 고자 _ 하 ㅂ니다 _ .',\n",
       " '_ 저희 는 _ 끝내 주는 _ 타이 타 닉 _ 비디오 도 _ 있 기 ㄴ _ 하 ㅂ니다만 _ 뭐 .. 여기 서는 _ 눈 꼽 만큼 도 _ 보여주 ㄹ _ 생각 이 없 습니다 _ .',\n",
       " '_ _ 비 록 _ 타이 타 닉 이 _ 박스오피스 에서 _ 굉장 한 _ 실적 을 _ 거두 기 ㄴ _ 했 지만 _ 바다 가 _ 들리 ㅓ 주는 _ 이야기 _ 중 _ 가장 _ 재 밌 는 _ 것 은 _ 아니 ㅂ니다 _ .',\n",
       " '_ 문제 라면 _ 우리 는 _ 우리 가 _ 바다 를 _ 이미 _ 알고있 다고 _ 믿 는 거 죠 _ .',\n",
       " '_ 보통 _ 바다 가 _ 지구 의 _ 75 _ % _ 를 _ 감싸 고 _ 있 다는 _ 것 _ , _',\n",
       " '_ 지구상 _ 바다 의 _ 대부분 은',\n",
       " '_ 평균 _ 깊이 가 _ 2 마일 _ _ 정도 _ 된다 는 걸 _ 알고있 죠',\n",
       " '_ 그리 고 는 _ 해변 가 에 _ 가 거나 _ 이러 ㄴ _ 바닷가 의 _ 이미지 를 _ 보고 는 _ 바다 란 _ 그냥 _ 거대 한 _ 파란색 의 _ 아르 ㄴ 하게 _ 넘 실 거리 는 _ 파도 와 _ 조수 간 만 의 _ 차 가 있 다 _ 정도 만 _ 생각 하 죠 _ 사실 _ 그 _ 속 에 _ 무엇 이 _ 있 는 지는 _ 상상 도 _ 못하 는 거 죠 .. _ .',\n",
       " '_ 바닷속 에는 _ 지구상 _ 가장 _ 기 ㄴ _ 산맥 과',\n",
       " '_ 대부분 의 _ 생명체 들이 _ 있 고',\n",
       " '_ 대부분 의 _ 지진 과 _ 화산 활동 이 _ 바닷속 에는 _ 일어나 ㅂ니다 . _ 저 _ 바다 _ 밑 _ 바닥 에는',\n",
       " '_ 밀림 보다 도 _ 더 _ 많 은 _ 종류 의 _ 생명체 들이 _ 훨 씬 _ 높 은 _ 밀집 도 를 _ 형성 하 며 _ 살 고 _ 있 습니다 _ .',\n",
       " '_ 이러 ㄴ _ 친밀감 을 _ 주는 _ 매력적 이 ㄴ _ 멋 진 _ 모습 들 _ 또한 _ 대부분 은 _ 아직 _ 탐사 조차 _ 되지 _ 않 았 죠',\n",
       " '_ 당신 이 _ 홀 로 _ 해변 에 _ 서있 게 _ 된다 면 _ 자신 이 _ 아 주 _ 낯 선 _ 세계 의 _ 가장자리 에 _ 있다 는 걸 _ 알아 주시 ㅓㅆ 으면 _ 하 ㅂ니다 _ .',\n",
       " '_ 이렇 게 _ 낯 선 _ 세계 를 _ 탐험 하기 _ 위해서 _ 우리 는 _ 특별 한 _ 기술 들 을 _ 갖추 ㅓ야 만 _ 했어 ㅆ 죠 _ .',\n",
       " \"^ alvin 이 라는 _ 이름 의 _ 잠수함 이 _ 동원 되었 고 _ , _ 카메라 도 _ 사용 했 습니다 _ 카메라 는 ^ bill ^ lange 가 _ ' _ 소니_ ' _ 의 _ 협찬 으로 _ 개발 한 _ 특수 _ 카메라 이 ㅓㅆ 습니다\",\n",
       " '^ marcel ^ proust 가 _ 말하기 ㄹ _ \" _ 가장 _ 진실 된 _ 탐험 이란 _ 낯 선 _ 장소 를 _ 찾아가 는 _ 것이 _ 아니 라 _ 새로우 ㄴ _ 시각 을 _ 갖 는 _ 것이다 _ \" _ 라고 요',\n",
       " '_ 저희 를 _ 협찬 해 주신 _ 분 들 은 _ 단순 히 _ 바다 _ 아래 에 _ 무엇 이 _ 존재 하 고 _ 어떠 ㄴ _ 지형 이 _ 펼치 ㅓ지 ㅓ _ 있 는지 를 _ 알게 _ 해주 었 을 _ 뿐 만 아니 라 _ 지구 에 _ 사 는 _ 생명체 들 에 _ 대한 _ 생각 을 _ 새 로 이 _ 하게 _ 해주 었습니다',\n",
       " '_ 여기 _ 제 가 _ 좋아 하는 _ 해파리 과 _ 생물 이 _ 있 습니다 _ .',\n",
       " '_ 흥미로우 ㄴ 건 _ 이 녀석 은 _ 나름 _ 분업 화 된 _ 몸 을 _ 가지고있 는 건 데 요',\n",
       " '_ 그 로 인 해 _ 바다 에서 _ 가장 _ 기 ㄴ _ 생명체 가 _ 되었 죠 _ .',\n",
       " '_ 대 략 _ 1 50 피트 _ _ 가량 _ 돼 죠 _ .',\n",
       " '_ 지금 _ 각 기 _ 따로 _ 움직이 는 _ 개체 들이 _ 보이 시 나요 _ ? _',\n",
       " '_ 저 는 _ 이 런 게 _ 너무 _ 좋 더 라 구 요 _ .',\n",
       " '_ 마치 _ 낚시 _ 찌 _ 같 은거 ㅅ 들이 _ 아래 에 _ 달려 서 _ 까 딱 까 딱 거리 죠',\n",
       " '_ 촉수 들이 _ 주 렁 주 렁 _ 달려 서 _ 저 렇 게 _ 막 _ 움직이 ㅂ니다 _ .',\n",
       " '_ 이건 _ 군체 동물 이 ㅂ니다 _ .',\n",
       " '_ 각각 의 _ 파트 가 _ 다르 ㄴ _ 동물 들이 _ 서로 _ 연결 됨 으로써 _ 이러 ㄴ _ 하나 의 _ 생명체 를 _ 만드 는 거 ㅂ니다 _ .',\n",
       " '_ 앞 에는 _ 청사 초 롱 같 은거 ㅅ 도 _ 달려있 는데요 _ 빛 이 _ 필요 한 _ 순간 _ 사용할 수있 죠',\n",
       " '_ 지구상 의 _ 모든 _ 큰 _ 물고기 들 과 _ 물고기 _ 떼 의 _ 무게 를 _ 합치 ㅓ _ 한쪽 _ 저울 에 _ 달 고 _ 이러 ㄴ _ 해파리 과 _ 생명체 를 _ 다르 ㄴ쪽 에 _ 단 다면 _ 이 _ 녀석 들이 _ 압도적 으로 _ 무거우 ㄹ 거 ㅂ니다 _ .',\n",
       " '_ 이러 ㄴ _ 생명체 들이 _ 바다 속 _ 생명체 의 _ 대다수 를 _ 차지 하 죠 _ .',\n",
       " '_ 이건 _ 죽음 의 _ 엑 스윙 _ 해파리 인 데 요',\n",
       " '_ _ 교미 와 _ 의사소통 을 위해 _ 이렇 게 _ 빛 을 _ 발 하 ㅂ니다 _ .',\n",
       " '_ 해파리 에 _ 대한 _ 방대 한 _ 자료 는 _ 아직 _ 보이 ㅓ 드리 지도 _ 못하 ㅣㅆ 습니다 _ .',\n",
       " '_ 해파리 들 은 _ 너무 나 _ 다양 한 _ 크기 와 _ 형태 를 _ 가 지고 _ 있 죠 _ .',\n",
       " '_ 우리 는 _ 잊 고 ㄴ _ 하 ㅂ니다 _ , _ 바다 가 _ 수천 미터 _ 이상 의 _ 깊이 라는 것 과 _ 우리 가 _ 아 는 _ 바다 의 _ 생명 들이 _ 대부분 이 _ 해수면 에서 _ 60 _ ~ _ 1 00 m 이내 의 _ 얕 은 _ 물 에 _ 몰려있 으며 _ 그 _ 아래 에서 부터 _ 해저 면 까지 에 _ 대 해서 는 _ 전혀 _ 모른 다는 _ 사실 을 요',\n",
       " '_ 그리 고 _ 이러 한 _ 동물 들이 _ 우리 가 _ 탐험 하지 _ 못하 ㄴ _ 종류 들이 ㅂ니다 _ 바다 _ 밑 _ 3 차원 적 _ 공간 에서 _ 중력 이 _ 거 의 _ 없 는 _ 환경 에서 _ 살 고 _ 있 는 _ 동물 들 _ 말 이 에요',\n",
       " '_ 아 마 _ 거대 _ 오징어 같 은거 ㅅ 들 은 _ 들어보 시 ㅓㅆ 을 거 ㅂ니다 _ 하 지만 _ 이 _ 동물 들 _ 중 _ 일부 는 _ 40 _ ~ _ 50 미터 까지 _ 자라나 죠',\n",
       " '_ 그리 고 _ 이 들 은 _ 거 의 _ 연구 조차 _ 되지 _ 않 았 죠 _ .',\n",
       " '_ 이 녀석 은 _ 문어 처럼 _ 생기 ㅓ 서 _ 제일 _ 좋아 하는 _ 녀석 중 _ 하나 인 데 요',\n",
       " '_ 머리 부분 이 _ 매우 _ 투명 하 ㅂ니다',\n",
       " '_ 그리 고 _ 퍼 럭 이 는 _ 귀 를 _ 이용 해서 _ 우아 하게 _ 수영 하 ㅂ니다 _ .',\n",
       " '_ 이 들 _ 모두 가 _ 대부분 의 _ 해저 면 _ , _ 그리 고 _ 가장 _ 깊 은 _ 곳 에서도 _ 발견 되 ㅂ니다 _ .',\n",
       " '_ 이 들 의 _ 크기 는 _ 2 _ ~ _ 3 센티미터 부터 _ 50 _ ~ _ 60 센티미터 까지 _ 다양 하 ㅂ니다 _ .',\n",
       " '_ 잠수함 _ 바로 _ 앞 까지 _ 와서 는 _ 잠수함 _ 창문 _ 넘 어 _ 우리 들 을 _ 바라보 고 는 _ 하 ㅂ니다 _ .',\n",
       " '_ 이건 _ 완전 _ 세상 _ 속 의 _ 또 다르 ㄴ _ 세상 이 죠 . _ 몇 가지 _ 더 _ 보이 ㅓ 드리 죠 _ .',\n",
       " '_ 요 녀석 은 _ 중앙 해령 _ 에서 _ 아래 로 _ 내려가 던 중 _ 발견 한 _ 녀석 이 ㅂ니다 . _ _',\n",
       " '_ 바다 속 _ 수탉 같 은 _ 녀석 이 죠',\n",
       " '_ 요 녀석 은 _ 어찌 보면 _ 굉장 히 _ 신사 같 아 _ 보이 죠',\n",
       " '_ 오 _ ~ _ 내 사랑 _ 잘생기 ㅓㅆ 죠 _ ? _',\n",
       " '_ 지금 _ 보고 _ 계시 ㄴ 건 _ 말 하자 면 _ 과학적 _ 자료 들이 ㅂ니다 _ .',\n",
       " '_ 과학적 _ 목적 을 _ 위해 _ 우리 가 _ 모으 ㄴ _ 자료 들이 죠 _ .',\n",
       " '_ 그리 고 _ 이러 ㄴ _ 이 녀석 들이 _ 살고있 는 곳 에서 _ 발견 된 _ 이러 ㄴ _ 녀석 들 의 _ 사진 을 _ 과학자 들 에게 _ 제공 하는 게 ^ bill 이 _ 하는 _ 역할 _ 중 의 _ 하나 이 구 요 _ .',\n",
       " '_ 우리 는 _ 이 _ 녀석 들 을 _ 잡지 는 _ 않 습니다 _ .',\n",
       " '_ 그 저 _ 우리 ㄴ _ 바라보 ㄹ _ 뿐 이거 죠 _ .',\n",
       " '_ 그럼 _ 조이 스틱 을 _ 이용 해서 _ 우리 의 _ 가상 _ 지구 를 _ 탐험 해보 겠습니다 _ 조이 스틱 을 _ 이용 해 _ 지구 _ 여기저기 를 _ 바라보 는 건 데 요 _ .',\n",
       " '_ 중앙 해령 의 _ 산등성이 를 _ 돌아다니 ㅓ 보 겠습니다 . _ 64 ˅ 0 00 Km _ 길이 의 _ 대사 ㄴ 맥 이 죠',\n",
       " '_ 해령 정상 에서 _ 수면 까지 의 _ 평균 _ 깊이 는 _ 2 . 4 Km _ 정도 _ 되 ㅂ니다 _ .',\n",
       " '_ 대서양 을 _ 거치 ㅓ 서 .. 아 _ 저기 _ 산 _ 등 성 이 가 _ 보이 죠 _ 캐리 비 안 해오 ㅏ _ 중앙 _ 아메리카 를 _ 넘어서 _ 여기 _ 태평양 에서 _ 끝 이 _ 나 ㅂ니다 . _ 북쪽 으로 _ 9 도 가량 _ 되 네요 _ .',\n",
       " '_ 저희 는 _ 수중 _ 음파 탐지 기를 _ 동원 해서 _ 이 _ 해저 _ 산맥 들 의 _ 지도 를 _ 작성 했 습니다 . _ 그리 고 _ 이 게 _ 그중 _ 일부 이 죠 _ .',\n",
       " '_ 우리 ㄴ _ 지금 _ 오르 ㄴ편 _ 해저 _ 절벽 을 _ 타 고 _ 가고 있 는데요',\n",
       " '_ 이 _ 양쪽 _ 계곡 의 _ 산봉우리 들 의 _ 높이 는 _ 대부분 _ 알프스 산맥 보다 _ 훨 씬 _ 높 습니다 _ .',\n",
       " '_ 그리 고 _ 아직 _ 수백 _ 수천 개 에 _ 이르 는 _ 해저 산맥 들이 _ 아직 _ 지도 화 되지 _ 않 은 _ 채 _ 남아있 습니다 _ .',\n",
       " '_ 여기 ㄴ _ 화산 지역 인 데 요',\n",
       " '_ 척도 를 _ 확대 해 _ 내려가 다 보면',\n",
       " '_ 결국 _ 이 런 곳 에 _ 다다르 게 _ 되 ㅂ니다 _ .',\n",
       " '_ 이건 _ 우리 _ 로봇 ^ jason 의 _ 아이콘 인 데 요',\n",
       " '_ 여러분 도 _ 이렇 게 _ 방 에 _ 앉아 _ 조이 스틱 과 _ 헤드셋 을 _ 이용 해 _ 로봇 을 _ 타 고 _ 실제 로 _ 해저 바닥 을 _ 실시간 으로 _ 돌아다니 ㄹ _ 수 _ 있 습니다 _ .',\n",
       " '_ 저희 가 ^ wood s ^ hole 에서 _ 파트너 들 과 _ 진행 하려 는 _ 작업 _ 중 _ 하나 가 _ 이러 ㄴ _ 가상 의 _ 세계 를 _ 아직 _ 탐사 되지 _ 않 은 _ 지역 들 을 _ , _ 실험실 로 _ 다시 _ 가져오 는 거 죠 _ .',\n",
       " '_ 왜냐 면 _ 지금 은 _ 자료 가 _ 작 은 _ 부분 들 로 _ 흩어지 ㅓ _ 있 기 _ 때문 이 죠',\n",
       " '_ 이렇 게 _ 소리 _ , _ 비디오 _ , _ 사진 _ , _ 혹 은 _ 화학적 _ 센서 를 _ 이용 한 _ 자료 들 을 _ 모 았 지만 _ 모든 걸 _ 아직 _ 완벽 한 _ 한장 의 _ 그림 으로는 _ 만들 지 _ 못하 ㅣㅆ 습니다 _ .',\n",
       " '_ 이 게 ^ bill 의 _ 카메라 가 _ 가장 _ 빛 을 _ 발 하던 _ 날인 데 요',\n",
       " '_ 이 게 _ 바로 _ 해저 _ 분출 공 _ 이 ㅂ니다 _ .',\n",
       " '_ 그리 고 _ 이건 _ 수소 와 _ 황 화물 들 로 _ 가득 _ 차 있 는 _ 연기 이 ㅂ니다 . _ 심해 의 _ 화산 지역 에서 _ 뿜 어지 ㅓ _ 나오 는 것 들이 ㄴ 데 요',\n",
       " '_ 온도 는 _ 섭 씨 _ 3 10 _ ~ _ 3 80 도 _ 가량 _ 되 구 요',\n",
       " '_ 모두 _ 바다 _ 아래 _ 1 . 5 _ ~ _ 3 마일 에서 _ 발견 할 _ 수 _ 있 는 _ 것이 ㅂ니다 _ .',\n",
       " '_ 저희 는 _ 이 게 _ 60 _ , _ 70 년 대 의 _ 화산 들 이라 _ 생각 했 는데요',\n",
       " '_ 어 쩌 다 _ 이 게 _ 아직 까지 _ 존재 한다 는 _ 힌트 를 _ 얻 을 _ 수 _ 있 었습니다 . _ 화산 활동 이 _ 있 으면 _ 물 이 _ 심해 _ 바닥 의 _ 틈 으로 _ 들어가 는데요 _ 때문 에 _ 물 이 _ 마그마 와 _ 만나 게 _ 되 면 _ 이 _ 축 을 _ 따라 _ 열 을 _ 발산 하게 _ 되 ㅂ니다 _ .',\n",
       " '_ 저희 는 _ 황화수소 가 _ 그렇게 _ 풍부 하리 라고 _ 생각 치 는 _ 않 았 습니다 _ .',\n",
       " \"_ ' _굴뚝_ ' _ 이 라고 _ 우리 가 _ 부르 는 _ 이것 에 _ 대 해 _ , _ 우리 는 _ 전혀 _ 모르 고 _ 있 었습니다 _ .\",\n",
       " '_ 이것 이 _ 열 수 _ 분출 공 _ 중 _ 하나 이 ㅂ니다 _ .',\n",
       " '_ 화씨 _ 6 00 도 의 _ 물 이 _ 지구 로부터 _ 분출 되 ㅂ니다 _ .',\n",
       " '_ 우리 _ 양 _ 옆 으로는 _ 알프스 보다 _ 더 _ 높 은 _ 산 이 _ 있 습니다 . _ 그래 서 _ 이곳 의 _ 환경 은 _ 매우 _ 드라마틱 하 죠 _ .',\n",
       " '_ 이 _ 하야 ㄴ _ 물질 은 _ 박테리아 의 _ 일종 인 데 요 _ 섭 씨 _ 1 80 도 에서 _ 잘 _ 자라 ㅂ니다 _ .',\n",
       " '_ 가장 _ 흥미로우 ㄴ _ 점 은 _ 바로 _ 우리 가 _ 해저 면 에서 _ 보 는 _ 것 _ , _ 그러 니까 _ 바다 _ 속 에서의 _ 화산 _ 폭발 _ 이 후에 _ 가장 _ 처음 _ 보 는 _ 것이 _ 박테리아 _ 라는 _ 거 죠 _ .',\n",
       " '_ 그리 고 _ 우리 는 _ 이 게 _ 대체 _ 여기 에 _ 어떻게 _ 내려오 ㅏㅆ 을까 에 _ 대 해 _ 아 주 _ 오래 ㅅ 동안 _ 궁금해 했 습니다 _ .',\n",
       " '_ 현재 로서 _ 저희 가 _ 찾아내 ㄴ _ 것 은 _ 아 마 _ 지구 _ 속 에서 _ 나오 지 _ 않 을까 _ 하는 _ 것이 ㅂ니다 _ .',\n",
       " '_ 단지 _ 지구 _ 속 에서 _ 나오 ㄹ _ 뿐 _ 아니 라 _ 그러 니까 _ , _ 화산 _ 활동 을 _ 통 해 _ 만들어지 ㄴ _ 생물 일 _ 뿐 만 _ 아니 라 _ 이 _ 박테리아 들이 _ 생물 _ 군락 _ 형성 을 _ 뒷받침 한다 는 _ 거 죠 _ .',\n",
       " '_ 이곳 의 _ 압력 은 _ 1 평 방 인치 당 _ 40 00 파운드 이 ㅂ니다 _ .',\n",
       " '_ 해수면 으로 부터 _ 0 . 5 _ ~ _ 3 마일 _ 아래 부터는 _ 햇볕 이 _ 단 _ 한 _ 번 도 _ 비추 ㄴ _ 적 이 _ 없 습니다 _ .',\n",
       " '_ 생명체 를 _ 구성 하는 _ 모든 _ 에너지 는 _ 지구 내부 로부터 _ 나오 ㅂ니다 _ , _ 즉 _ 화학 합성 이 죠 _ .',\n",
       " '_ 우리 는 _ 생명체 들 의 _ 밀집 도 가 _ 상당 히 _ 높 다는 _ 것 도 _ 알 _ 수 _ 있 습니다 _ .',\n",
       " '_ 이것 들 은 _ 서고 ㅏ ㄴ 충 이 라고 _ 하 는데요 _ .',\n",
       " '_ 이 _ 벌레 들 은 _ 소화기 관 이 _ 없 습니다 . _ 입 도 _ 없 죠 _ .',\n",
       " '_ 하 지만 _ 이 들 은 _ 두 _ 종류 의 _ 아가미 _ 구조 를 _ 가 지고 _ 있 습니다 _ .',\n",
       " '_ 하나 는 _ 심해 수 로부터 _ 산소 를 _ 얻어내 기 _ 위 한 _ 것이 고 _ , _ 다르 ㄴ _ 하나 는 _ 이러 ㄴ _ 화학 합성 _ 박테리아 의 _ 집 _ 역할 을 _ 하는 _ 것이 ㅂ니다 . _ 열 수 의 _ 흐름 을 _ 잡 는 _ 건 데 요 _ 바닥 에서 _ 올라오 는 _ 뜨거우 ㄴ _ 물 이 _ 보이 는데요 _ 그러 면 _ 그거 ㄹ _ 단순 당 _ 형태 로 _ 바꾸 ㅓ 서 _ 서고 ㅏ ㄴ 충 이 _ 소화 _ 할 _ 수 _ 있 도록 _ 하는 _ 것이 죠',\n",
       " '_ 보이 시 죠 - _ 이 _ 아래 에 _ 살 고 _ 있 는 _ 게이 ㅂ니다 _ .',\n",
       " '_ 이러 ㄴ _ 벌레 _ 끝 을 _ 가 까 스 로 _ 잡 았 습니다',\n",
       " '_ 보통 _ 벌레 들 은 _ 게 에 _ 닿 자마자 _ 확 _ 움 츠 러 _ 들 죠']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mX = [z.sub(' ',p.sub('',q.sub('',s))).strip() for s in X][:-1]\n",
    "mY = [z.sub(' ',p.sub('',q.sub('',s))).strip() for s in Y][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ted_data/to_train/ted_train.en', 'w') as f:\n",
    "    f.write('\\n'.join(X[:166213]))\n",
    "\n",
    "with open('ted_data/to_train/ted_train.ko', 'w') as f:\n",
    "    f.write('\\n'.join(Y[:166213]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nX = [s for s in mY if z1.search(s) is not None]\n",
    "len(nX), nX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(5, 6), match='\\\\'>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = \"일본 , \\ 인도 , 미국 , 프랑스 ,   \\'s 200b \\u200b 오스트레일리아 \"\n",
    "z1.search(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 671)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('^ mechanical _ ventilation _ , _ or _ assist ed _ ventilation _ , _ is _ the _ medical _ term _ for _ artificial _ ventilation _ where _ mechanical _ mean s _ are _ used _ to _ assist _ or _ replace _ spontaneous _ breath ing _ .',\n",
       " '_ 기계 환기 _ ( _ 機 _ 械 _ 換 _ 氣 _ , _ mechanical _ ventilation _ ) _ 은 _ 자발적 이 ㄴ _ 호흡 을 _ 보조 하 거나 _ 대체 하기 _ 위해 _ 기계적 _ 수단 이 _ 사용 되는 _ 인공 환기 이 다 _ .')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkk = 444   #512  #233('\\'s')   #247    #345\n",
    "X[kkk],Y[kkk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p = re.compile('[\\`\\^]')\n",
    "Xsbol = [s for s in X if p.search(s) is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295819"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xsbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('to_preproc/totrain_en_EL', 'r') as f:\n",
    "    X = f.read().split('\\n')[:-2]\n",
    "\n",
    "with open('to_preproc/totrain_ko_EL', 'r') as f:\n",
    "    Y = f.read().split('\\n')[:-2]\n",
    "    \n",
    "mX = [s for i,s in enumerate(X) if i%31 not in [7,17]]\n",
    "dX1 = [s for i,s in enumerate(X) if i%31 == 7]\n",
    "tX1 = [s for i,s in enumerate(X) if i%31 == 17]\n",
    "mY = [s for i,s in enumerate(Y) if i%31 not in [7,17]]\n",
    "dY1 = [s for i,s in enumerate(Y) if i%31 == 7]\n",
    "tY1 = [s for i,s in enumerate(Y) if i%31 == 17]\n",
    "\n",
    "with open('to_preproc/train4.en', 'w') as f:\n",
    "    f.write('\\n'.join(mX))\n",
    "\n",
    "with open('to_preproc/train4.ko', 'w') as f:\n",
    "    f.write('\\n'.join(mY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('to_preproc/totrain_en_talk', 'r') as f:\n",
    "    X = f.read().split('\\n')[:-2]\n",
    "\n",
    "with open('to_preproc/totrain_ko_talk', 'r') as f:\n",
    "    Y = f.read().split('\\n')[:-2]\n",
    "    \n",
    "mX = [s for i,s in enumerate(X) if i%5000 not in [7,17]]\n",
    "dX2 = [s for i,s in enumerate(X) if i%5000 == 7]\n",
    "tX2 = [s for i,s in enumerate(X) if i%5000 == 17]\n",
    "mY = [s for i,s in enumerate(Y) if i%5000 not in [7,17]]\n",
    "dY2 = [s for i,s in enumerate(Y) if i%5000 == 7]\n",
    "tY2 = [s for i,s in enumerate(Y) if i%5000 == 17]\n",
    "\n",
    "with open('to_preproc/train5.en', 'w') as f:\n",
    "    f.write('\\n'.join(mX))\n",
    "\n",
    "with open('to_preproc/train5.ko', 'w') as f:\n",
    "    f.write('\\n'.join(mY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,\n",
       " 42,\n",
       " ['^ the ^ ocean ^ viking _ , _ a _ rescue _ ship _ operat ed _ by ` msf _ and ` sos ^ medi tera nee _ that _ was _ carrying _ almost _ 3 00 _ migrant s _ , _ was _ quarantin ed _ for _ 14 _ days _ in ^ po zz allo _ , ^ sicily _ .',\n",
       "  '^ corticosteroid s _ by _ mouth _ improve _ the _ chance _ of _ recovery _ and _ decreas e _ the _ overall _ duration _ of _ symptoms _ .'],\n",
       " ['` msf 와 ` sos _ 메 디 테 라 네 가 _ 운영 하는 _ 구조 선인 _ 오 션 _ 바이킹 은 _ 시칠리아 의 _ 포 잘 로 에서 _ 14 일 _ 간 _ 격리 되었 다 _ .',\n",
       "  '_ 구강 _ 코르티코스테로이드 는 _ 회복 의 _ 가능성 을 _ 높이 고 _ 증상 의 _ 지속 기간 을 _ 줄이 ㄴ 다 _ .'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX = dX1 + dX2\n",
    "dY = dY1 + dY2\n",
    "tX = tX1 + tX2\n",
    "tY = tY1 + tY2\n",
    "len(dX), len(dY), dX[:2], dY[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('to_preproc/dev_toAdd.en', 'w') as f:\n",
    "    f.write('\\n'.join(dX))\n",
    "\n",
    "with open('to_preproc/dev_toAdd.ko', 'w') as f:\n",
    "    f.write('\\n'.join(dY))\n",
    "\n",
    "with open('to_preproc/test_toAdd.en', 'w') as f:\n",
    "    f.write('\\n'.join(tX))\n",
    "\n",
    "with open('to_preproc/test_toAdd.ko', 'w') as f:\n",
    "    f.write('\\n'.join(tY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
